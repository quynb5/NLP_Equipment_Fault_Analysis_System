"""
Data Preparation â€” Thu tháº­p & augment dá»¯ liá»‡u training.
=========================================================
3 nguá»“n dá»¯ liá»‡u:
  Source 1: FAULT_REFERENCES samples tá»« phobert_engine.py
  Source 2: test_dataset.json (labeled)
  Source 3: Data augmentation (Ä‘áº£o tá»«, thay tá»« Ä‘á»“ng nghÄ©a)
"""
import json
import random
import re
from pathlib import Path

from backend.training.config import (
    TEST_DATASET_PATH,
    AUGMENT_ENABLED,
    AUGMENT_MULTIPLIER,
    RANDOM_STATE,
)

random.seed(RANDOM_STATE)


# ========================
# LABEL NORMALIZATION
# ========================
# FAULT_REFERENCES dÃ¹ng "BÃ¬nh thÆ°á»ng",
# test_dataset dÃ¹ng "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh".
# Chuáº©n hÃ³a vá» label thá»‘ng nháº¥t (dÃ¹ng test_dataset convention).
LABEL_MAP = {
    "BÃ¬nh thÆ°á»ng": "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh",
}


def normalize_label(label: str) -> str:
    """Chuáº©n hÃ³a label vá» tÃªn thá»‘ng nháº¥t."""
    return LABEL_MAP.get(label, label)


# ========================
# SOURCE 1: FAULT_REFERENCES
# ========================
def load_fault_references() -> list[dict]:
    """
    Extract samples tá»« FAULT_REFERENCES trong phobert_engine.py.
    Return: [{"description": ..., "label": ...}, ...]
    """
    from backend.core.phobert_engine import FAULT_REFERENCES

    data = []
    for fault_type, fault_data in FAULT_REFERENCES.items():
        label = normalize_label(fault_type)
        for sample in fault_data["samples"]:
            data.append({"description": sample, "label": label})

    print(f"  ğŸ“š Source 1 (FAULT_REFERENCES): {len(data)} samples")
    return data


# ========================
# SOURCE 2: TEST DATASET
# ========================
def load_test_dataset() -> list[dict]:
    """
    Load test_dataset.json.
    Return: [{"description": ..., "label": ...}, ...]
    """
    with open(TEST_DATASET_PATH, "r", encoding="utf-8") as f:
        raw = json.load(f)

    data = [
        {"description": item["description"], "label": normalize_label(item["true_label"])}
        for item in raw
    ]
    print(f"  ğŸ“š Source 2 (test_dataset.json): {len(data)} samples")
    return data


# ========================
# SOURCE 3: DATA AUGMENTATION
# ========================

# Tá»« Ä‘á»“ng nghÄ©a cho thiáº¿t bá»‹ cÃ´ng nghiá»‡p
SYNONYM_MAP = {
    "motor": ["Ä‘á»™ng cÆ¡", "mÃ¡y", "mÃ´ tÆ¡"],
    "Ä‘á»™ng cÆ¡": ["motor", "mÃ¡y", "mÃ´ tÆ¡"],
    "thiáº¿t bá»‹": ["mÃ¡y mÃ³c", "mÃ¡y", "há»‡ thá»‘ng"],
    "mÃ¡y": ["thiáº¿t bá»‹", "motor", "há»‡ thá»‘ng"],
    "nÃ³ng": ["nhiá»‡t cao", "nÃ³ng báº¥t thÆ°á»ng", "phÃ¡t nhiá»‡t"],
    "rung": ["rung láº¯c", "rung Ä‘á»™ng", "dao Ä‘á»™ng"],
    "rung máº¡nh": ["rung láº¯c dá»¯ dá»™i", "rung Ä‘á»™ng máº¡nh"],
    "tiáº¿ng kÃªu": ["Ã¢m thanh", "tiáº¿ng á»“n", "tiáº¿ng Ä‘á»™ng"],
    "há»ng": ["hÆ° há»ng", "bá»‹ há»ng", "trá»¥c tráº·c"],
    "rÃ² rá»‰": ["cháº£y", "rá»‰", "xÃ¬"],
    "chÃ¡y": ["bá»‘c chÃ¡y", "chÃ¡y khÃ©t"],
    "khÃ³i": ["bá»‘c khÃ³i", "khÃ³i bá»‘c"],
    "mÃ¹i khÃ©t": ["mÃ¹i chÃ¡y", "mÃ¹i chÃ¡y khÃ©t"],
    "báº¥t thÆ°á»ng": ["láº¡", "khÃ¡c thÆ°á»ng", "khÃ´ng bÃ¬nh thÆ°á»ng"],
    "nghiÃªm trá»ng": ["náº·ng", "tráº§m trá»ng", "nguy hiá»ƒm"],
    "dáº§u": ["dáº§u nhá»›t", "dáº§u bÃ´i trÆ¡n", "dáº§u thá»§y lá»±c"],
    "gioÄƒng": ["phá»›t", "seal", "roÄƒng"],
    "bu lÃ´ng": ["á»‘c vÃ­t", "bulÃ´ng"],
    "dÃ¢y Ä‘ai": ["Ä‘ai truyá»n Ä‘á»™ng", "belt"],
    "báº¡c Ä‘áº¡n": ["vÃ²ng bi", "á»• bi", "bearing"],
    "vÃ²ng bi": ["báº¡c Ä‘áº¡n", "á»• bi"],
    "cháº­p Ä‘iá»‡n": ["cháº­p máº¡ch", "ngáº¯n máº¡ch"],
    "quÃ¡ táº£i": ["vÆ°á»£t táº£i", "overload"],
}


def _augment_swap_words(text: str) -> str:
    """Äáº£o vá»‹ trÃ­ 2 tá»« ngáº«u nhiÃªn trong cÃ¢u."""
    words = text.split()
    if len(words) < 3:
        return text
    i, j = random.sample(range(len(words)), 2)
    words[i], words[j] = words[j], words[i]
    return " ".join(words)


def _augment_synonym(text: str) -> str:
    """Thay 1 tá»« báº±ng tá»« Ä‘á»“ng nghÄ©a."""
    words = text.split()
    # TÃ¬m tá»«/cá»¥m tá»« cÃ³ thá»ƒ thay
    candidates = []
    for key in SYNONYM_MAP:
        if key in text:
            candidates.append(key)

    if not candidates:
        return _augment_swap_words(text)  # Fallback: Ä‘áº£o tá»«

    target = random.choice(candidates)
    replacement = random.choice(SYNONYM_MAP[target])
    return text.replace(target, replacement, 1)


def augment_data(data: list[dict], multiplier: int = 2) -> list[dict]:
    """
    Táº¡o dá»¯ liá»‡u augmented.
    Má»—i sample gá»‘c â†’ thÃªm `multiplier` samples (Ä‘áº£o tá»« + thay tá»« Ä‘á»“ng nghÄ©a).
    """
    if not AUGMENT_ENABLED:
        return []

    augmented = []
    for item in data:
        for _ in range(multiplier):
            method = random.choice([_augment_swap_words, _augment_synonym])
            new_text = method(item["description"])
            if new_text != item["description"]:
                augmented.append({
                    "description": new_text,
                    "label": item["label"],
                })

    print(f"  ğŸ“š Source 3 (Augmentation Ã—{multiplier}): {len(augmented)} samples")
    return augmented


# ========================
# MAIN: COLLECT ALL DATA
# ========================
def prepare_training_data() -> tuple[list[str], list[str]]:
    """
    Thu tháº­p & gá»™p toÃ n bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n.

    Returns:
        (texts, labels) â€” parallel lists
    """
    print("\nğŸ“¦ Preparing training data...")

    # Source 1
    source1 = load_fault_references()

    # Source 2
    source2 = load_test_dataset()

    # Source 3: augment tá»« cáº£ source 1 + source 2
    source3 = augment_data(source1 + source2, multiplier=AUGMENT_MULTIPLIER)

    # Gá»™p táº¥t cáº£
    all_data = source1 + source2 + source3

    # Shuffle
    random.shuffle(all_data)

    texts = [d["description"] for d in all_data]
    labels = [d["label"] for d in all_data]

    # Stats
    from collections import Counter
    label_counts = Counter(labels)
    print(f"\n  ğŸ“Š Tá»•ng: {len(texts)} samples, {len(label_counts)} classes")
    for label, count in sorted(label_counts.items()):
        print(f"     {label}: {count}")

    return texts, labels
