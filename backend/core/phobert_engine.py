"""
PhoBERT Engine - Vietnamese Industrial Equipment Fault Analysis
===============================================================
Pipeline: Vietnamese text â†’ Preprocessing â†’ PhoBERT Tokenization
           â†’ PhoBERT Encoding â†’ Semantic Fault Classification
           â†’ Severity Scoring â†’ Recommendation Generation

Sá»­ dá»¥ng PhoBERT (vinai/phobert-base) Ä‘á»ƒ encode mÃ´ táº£ thiáº¿t bá»‹,
sau Ä‘Ã³ so sÃ¡nh cosine similarity vá»›i cÃ¡c máº«u lá»—i Ä‘Ã£ Ä‘á»‹nh nghÄ©a
Ä‘á»ƒ phÃ¢n loáº¡i lá»—i vÃ  Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng.
"""

import re
import os
os.environ["CUDA_VISIBLE_DEVICES"] = ""  # Force CPU mode

import time
import unicodedata
import torch
from transformers import AutoModel, AutoTokenizer

from backend.core.base_engine import BaseNLPEngine, AnalysisResult


# ============================================================
# 1. PhoBERT MODEL LOADER
# ============================================================

_HF_MODEL_NAME = "vinai/phobert-base"

import pathlib as _pathlib
_MODEL_PATH = str(_pathlib.Path(__file__).resolve().parent.parent / "resources" / "phobert-base")


def _load_model():
    """Load PhoBERT tá»« local path, náº¿u khÃ´ng cÃ³ thÃ¬ download tá»« HuggingFace."""
    model_dir = _pathlib.Path(_MODEL_PATH)

    if model_dir.exists() and any(model_dir.iterdir()):
        # Load tá»« local path
        print(f"ğŸ”„ Äang táº£i PhoBERT tá»« local: {_MODEL_PATH}")
        try:
            tokenizer = AutoTokenizer.from_pretrained(_MODEL_PATH)
            model = AutoModel.from_pretrained(_MODEL_PATH)
            print("âœ… Load tá»« local thÃ nh cÃ´ng")
            return tokenizer, model
        except Exception as e:
            print(f"âš ï¸ Load tá»« local tháº¥t báº¡i: {e}")
            print("ğŸ”„ Sáº½ download láº¡i tá»« HuggingFace...")

    # Download tá»« HuggingFace vÃ  lÆ°u vÃ o _MODEL_PATH
    print(f"ğŸ”„ Äang download PhoBERT ({_HF_MODEL_NAME}) tá»« HuggingFace...")
    model_dir.mkdir(parents=True, exist_ok=True)
    tokenizer = AutoTokenizer.from_pretrained(_HF_MODEL_NAME)
    model = AutoModel.from_pretrained(_HF_MODEL_NAME)
    tokenizer.save_pretrained(_MODEL_PATH)
    model.save_pretrained(_MODEL_PATH)
    print(f"âœ… Download vÃ  lÆ°u thÃ nh cÃ´ng táº¡i: {_MODEL_PATH}")
    return tokenizer, model


_tokenizer, _model = _load_model()
_model.eval()  # Cháº¿ Ä‘á»™ inference

# Chá»n device
_device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
_model.to(_device)

print(f"âœ… PhoBERT ready on {_device}")


# ============================================================
# 2. FAULT REFERENCE DATABASE
# ============================================================

# CÃ¡c máº«u mÃ´ táº£ lá»—i tham chiáº¿u â€” PhoBERT sáº½ so sÃ¡nh semantic similarity
FAULT_REFERENCES = {
    "BÃ¬nh thÆ°á»ng": {
        "samples": [
            "thiáº¿t bá»‹ hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng á»•n Ä‘á»‹nh",
            "mÃ¡y cháº¡y tá»‘t khÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬",
            "hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng khÃ´ng cÃ³ tiáº¿ng á»“n láº¡",
            "má»i thá»© á»•n Ä‘á»‹nh khÃ´ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng",
            "thiáº¿t bá»‹ váº­n hÃ nh tá»‘t khÃ´ng rung khÃ´ng nÃ³ng",
            "mÃ¡y hoáº¡t Ä‘á»™ng Ãªm khÃ´ng cÃ³ mÃ¹i láº¡",
            "tÃ¬nh tráº¡ng tá»‘t nhiá»‡t Ä‘á»™ bÃ¬nh thÆ°á»ng",
            "motor cháº¡y Ãªm Ã¡i khÃ´ng cÃ³ tiáº¿ng Ä‘á»™ng láº¡",
            "hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng cháº¡y Ãªm Ã¡i",
            "mÃ¡y cháº¡y Ãªm khÃ´ng rung khÃ´ng nÃ³ng khÃ´ng mÃ¹i",
            "thiáº¿t bá»‹ cháº¡y á»•n Ä‘á»‹nh khÃ´ng cÃ³ báº¥t thÆ°á»ng gÃ¬",
            "hoáº¡t Ä‘á»™ng tá»‘t khÃ´ng cÃ³ sá»± cá»‘",
            "váº­n hÃ nh bÃ¬nh thÆ°á»ng khÃ´ng phÃ¡t hiá»‡n hÆ° há»ng",
            "mÃ¡y hoáº¡t Ä‘á»™ng tá»‘t khÃ´ng cáº§n báº£o trÃ¬",
            "táº¥t cáº£ chá»‰ sá»‘ bÃ¬nh thÆ°á»ng thiáº¿t bá»‹ á»•n Ä‘á»‹nh",
            # --- Negation & new patterns ---
            "motor váº­n hÃ nh trÆ¡n tru khÃ´ng cÃ³ tiáº¿ng á»“n báº¥t thÆ°á»ng nhiá»‡t Ä‘á»™ trong ngÆ°á»¡ng",
            "bÆ¡m nÆ°á»›c cháº¡y Ä‘á»u Ã¡p suáº¥t á»•n Ä‘á»‹nh khÃ´ng rung khÃ´ng nÃ³ng",
            "quáº¡t cÃ´ng nghiá»‡p hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng khÃ´ng phÃ¡t hiá»‡n dáº¥u hiá»‡u báº¥t thÆ°á»ng",
            "há»‡ thá»‘ng bÆ¡m thá»§y lá»±c váº­n hÃ nh á»•n Ä‘á»‹nh suá»‘t ca khÃ´ng rÃ² rá»‰ khÃ´ng tiáº¿ng kÃªu",
            "mÃ¡y nÃ©n khÃ­ cháº¡y tá»‘t khÃ´ng nÃ³ng báº¥t thÆ°á»ng cÃ´ng suáº¥t Ä‘áº¡t yÃªu cáº§u",
            "thiáº¿t bá»‹ khÃ´ng cÃ³ váº¥n Ä‘á» gÃ¬ thÃ´ng sá»‘ náº±m trong giá»›i háº¡n an toÃ n",
            "motor cháº¡y mÆ°á»£t mÃ  khÃ´ng rung láº¯c khÃ´ng mÃ¹i khÃ©t nhiá»‡t Ä‘á»™ bÃ¬nh thÆ°á»ng",
            "bÄƒng táº£i váº­n hÃ nh Ä‘Ãºng tá»‘c Ä‘á»™ thiáº¿t káº¿ khÃ´ng trÆ°á»£t khÃ´ng káº¹t",
            "há»‡ thá»‘ng cháº¡y Ãªm nhiá»‡t Ä‘á»™ á»•n Ä‘á»‹nh khÃ´ng rung khÃ´ng cÃ³ báº¥t thÆ°á»ng",
            "thiáº¿t bá»‹ cháº¡y á»•n Ä‘á»‹nh suá»‘t ca lÃ m viá»‡c khÃ´ng cÃ³ báº¥t thÆ°á»ng gÃ¬",
        ],
        "severity_base": 0.0,
        "is_normal": True,
        "description": "Thiáº¿t bá»‹ hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng, khÃ´ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng",
    },
    "QuÃ¡ nhiá»‡t": {
        "samples": [
            "thiáº¿t bá»‹ nÃ³ng báº¥t thÆ°á»ng nhiá»‡t Ä‘á»™ ráº¥t cao",
            "motor quÃ¡ nÃ³ng tá»a nhiá»‡t máº¡nh chÃ¡y tay",
            "nhiá»‡t Ä‘á»™ tÄƒng cao báº¥t thÆ°á»ng bá»ng tay nÃ³ng ran",
            "thiáº¿t bá»‹ bá»‘c hÆ¡i nÃ³ng khÃ³i nhiá»‡t tÄƒng",
            "vá» mÃ¡y nÃ³ng cháº£y quÃ¡ nhiá»‡t nghiÃªm trá»ng",
            "mÃ¡y nÃ³ng ran sá» vÃ o bá»ng da nhiá»‡t cao",
            "nhiá»‡t tá»a ra ráº¥t máº¡nh thiáº¿t bá»‹ quÃ¡ nÃ³ng",
            "vá» motor nÃ³ng dá»¯ dá»™i nhiá»‡t Ä‘á»™ vÆ°á»£t ngÆ°á»¡ng",
            "bÆ¡m thá»§y lá»±c nÃ³ng báº¥t thÆ°á»ng cháº¡m bá»ng tay",
            "nÃ³ng háº§m háº­p nhiá»‡t lÆ°á»£ng tá»a lá»›n báº¥t thÆ°á»ng",
            "nhiá»‡t tÄƒng liÃªn tá»¥c khÃ´ng giáº£m nÃ³ng bá»‘c hÆ¡i",
            "cáº£m biáº¿n nhiá»‡t bÃ¡o vÆ°á»£t ngÆ°á»¡ng thiáº¿t bá»‹ quÃ¡ nÃ³ng",
            "nhiá»‡t Ä‘á»™ cao báº¥t thÆ°á»ng nÃ³ng hÆ¡n bÃ¬nh thÆ°á»ng ráº¥t nhiá»u",
            "thiáº¿t bá»‹ phÃ¡t nhiá»‡t máº¡nh quÃ¡ má»©c cho phÃ©p",
            "motor nÃ³ng liÃªn tá»¥c khÃ´ng háº¡ nhiá»‡t dÃ¹ giáº£m táº£i",
            # --- New patterns ---
            "vá» motor nÃ³ng hÆ¡n bÃ¬nh thÆ°á»ng ráº¥t nhiá»u khi cháº¡m vÃ o",
            "nhiá»‡t Ä‘á»™ bá» máº·t thiáº¿t bá»‹ vÆ°á»£t ngÆ°á»¡ng cáº£nh bÃ¡o sensor bÃ¡o quÃ¡ nhiá»‡t",
            "motor phÃ¡t nhiá»‡t liÃªn tá»¥c dÃ¹ táº£i nháº¹ há»‡ thá»‘ng lÃ m mÃ¡t khÃ´ng hiá»‡u quáº£",
            "bÆ¡m nÃ³ng ran khÃ´ng cháº¡m Ä‘Æ°á»£c nhiá»‡t káº¿ Ä‘o vÆ°á»£t 90 Ä‘á»™",
            "nhiá»‡t tá»a ra tá»« thiáº¿t bá»‹ lá»›n báº¥t thÆ°á»ng dáº§u bÃ´i trÆ¡n bá»‹ loÃ£ng",
            "thiáº¿t bá»‹ nÃ³ng bá»©c xáº¡ quáº¡t táº£n nhiá»‡t cháº¡y háº¿t cÃ´ng suáº¥t khÃ´ng giáº£m nhiá»‡t",
            "thÃ¢n mÃ¡y nÃ³ng hÆ¡n má»©c cho phÃ©p cáº£m biáº¿n nhiá»‡t liÃªn tá»¥c cáº£nh bÃ¡o",
            "mÃ¡y nÃ©n nÃ³ng quÃ¡ hÆ¡i nÃ³ng bá»‘c lÃªn máº¡nh nhiá»‡t tÄƒng báº¥t thÆ°á»ng",
            "motor quÃ¡ nÃ³ng nÃ³ng báº¥t thÆ°á»ng so vá»›i má»i khi nhiá»‡t cao",
            "mÃ¡y bá»‘c hÆ¡i nÃ³ng nhiá»‡t tÄƒng liÃªn tá»¥c khÃ´ng giáº£m quÃ¡ nhiá»‡t",
        ],
        "severity_base": 0.7,
        "description": "Thiáº¿t bá»‹ hoáº¡t Ä‘á»™ng á»Ÿ nhiá»‡t Ä‘á»™ cao báº¥t thÆ°á»ng",
    },
    "Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi": {
        "samples": [
            "rung máº¡nh kÃ¨m tiáº¿ng kim loáº¡i va cháº¡m",
            "tiáº¿ng kÃªu láº¡ rung láº¯c máº¡nh tiáº¿ng cá» sÃ¡t",
            "rung báº¥t thÆ°á»ng tiáº¿ng rÃ­t cao tiáº¿ng kim loáº¡i",
            "rung Ä‘á»™ng máº¡nh kÃ¨m tiáº¿ng va Ä‘áº­p báº¡c Ä‘áº¡n vÃ²ng bi",
            "tiáº¿ng lÃ¡ch cÃ¡ch rung liÃªn tá»¥c giáº­t cá»¥c",
            "rung láº¯c kÃ¨m tiáº¿ng cá» kim loáº¡i bÃªn trong motor",
            "tiáº¿ng kÃªu rÃ­t tá»« vÃ²ng bi rung láº¯c máº¡nh",
            "trá»¥c mÃ¡y rung giáº­t cá»¥c tiáº¿ng kÃªu láº¡ liÃªn tá»¥c",
            "tiáº¿ng kim loáº¡i cá» sÃ¡t máº¡nh rung giáº­t liÃªn tá»¥c",
            "báº¡c Ä‘áº¡n phÃ¡t tiáº¿ng kÃªu rÃ­t rung láº¯c tÄƒng dáº§n",
            "á»• bi kÃªu to rung láº¯c rÃµ rá»‡t khi váº­n hÃ nh",
            "tiáº¿ng cá» sÃ¡t kim loáº¡i cáº£m nháº­n rung máº¡nh á»Ÿ trá»¥c",
            "motor giáº­t cá»¥c liÃªn tá»¥c tiáº¿ng lÃ¡ch cÃ¡ch báº¡c Ä‘áº¡n",
            "rung dá»¯ dá»™i kÃ¨m Ã¢m thanh kim loáº¡i va cháº¡m á»• bi",
            "phÃ¡t hiá»‡n rung báº¥t thÆ°á»ng tiáº¿ng rÃ­t cao tá»« vÃ²ng bi",
            # --- New patterns (negation + technical) ---
            "motor khÃ´ng nÃ³ng nhÆ°ng rung láº¯c máº¡nh phÃ¡t tiáº¿ng kÃªu kim loáº¡i",
            "nghe tiáº¿ng rÃ­t tá»« vá»‹ trÃ­ báº¡c Ä‘áº¡n motor rung tÄƒng dáº§n theo thá»i gian",
            "vÃ²ng bi phÃ­a sau motor cÃ³ dáº¥u hiá»‡u mÃ²n tiáº¿ng kÃªu rÃ¨ khi quay",
            "trá»¥c motor lá»ng láº»o láº¯c qua láº¡i khi quay nghi ngá» báº¡c Ä‘áº¡n mÃ²n",
            "rung táº§n sá»‘ cao phÃ¡t ra tá»« á»• trá»¥c dáº§u má»¡ bÃ´i trÆ¡n bá»‹ biáº¿n mÃ u",
            "motor rung kÃ¨m tiáº¿ng láº¡ch cáº¡ch nhá»‹p Ä‘á»u Ä‘áº·n khi quay cháº­m",
            "á»• bi phÃ¡t ra tiáº¿ng Ã¹ liÃªn tá»¥c bá» máº·t trá»¥c bá»‹ xÆ°á»›c",
            "khÃ´ng nÃ³ng khÃ´ng khÃ©t chá»‰ rung máº¡nh kÃ¨m tiáº¿ng kim loáº¡i á»• bi",
            "motor rung láº¯c báº¥t thÆ°á»ng á»• trá»¥c phÃ¡t tiáº¿ng kÃªu nghi báº¡c Ä‘áº¡n há»ng",
            "tiáº¿ng rÃ­t cao tá»« báº¡c Ä‘áº¡n kÃ¨m rung khi táº£i tÄƒng",
        ],
        "severity_base": 0.75,
        "description": "Rung Ä‘á»™ng + tiáº¿ng kim loáº¡i â€” nghi ngá» há»ng báº¡c Ä‘áº¡n hoáº·c vÃ²ng bi",
    },
    "ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor": {
        "samples": [
            "mÃ¹i khÃ©t chÃ¡y kÃ¨m nhiá»‡t Ä‘á»™ ráº¥t cao bá»‘c khÃ³i",
            "mÃ¹i chÃ¡y mÃ¹i nhá»±a chÃ¡y nÃ³ng báº¥t thÆ°á»ng bá»‘c khÃ³i",
            "khÃ©t mÃ¹i dáº§u chÃ¡y quÃ¡ nhiá»‡t nghiÃªm trá»ng khÃ³i",
            "motor chÃ¡y mÃ¹i khÃ©t nÃ³ng cháº£y tia lá»­a Ä‘iá»‡n",
            "cuá»™n dÃ¢y chÃ¡y mÃ¹i cao su chÃ¡y bá»‘c khÃ³i nhiá»‡t cao",
            "bá»‘c khÃ³i Ä‘en mÃ¹i chÃ¡y khÃ©t ná»“ng náº·c tá»« motor",
            "mÃ¹i khÃ©t chÃ¡y ráº¥t náº·ng kÃ¨m khÃ³i bá»‘c máº¡nh",
            "khÃ³i bá»‘c ra tá»« cuá»™n dÃ¢y motor mÃ¹i chÃ¡y ná»“ng",
            "motor phÃ¡t mÃ¹i khÃ©t dá»¯ dá»™i bá»‘c khÃ³i nÃ³ng cháº£y",
            "phÃ¡t hiá»‡n khÃ³i mÃ¹i chÃ¡y tia lá»­a tá»« cuá»™n dÃ¢y",
            "mÃ¹i dáº§u chÃ¡y khÃ©t tá»« motor bá»‘c khÃ³i Ä‘en nÃ³ng cao",
            "motor bá»‘c khÃ³i mÃ¹i chÃ¡y nhá»±a nÃ³ng khÃ´ng cháº¡m Ä‘Æ°á»£c",
            "cuá»™n dÃ¢y motor chÃ¡y Ä‘en mÃ¹i khÃ©t bá»‘c khÃ³i liÃªn tá»¥c",
            "thiáº¿t bá»‹ bá»‘c khÃ³i mÃ¹i khÃ©t chÃ¡y cá»±c ká»³ nÃ³ng",
            "mÃ¹i chÃ¡y khÃ©t ná»“ng náº·c motor nÃ³ng cháº£y bá»‘c khÃ³i",
            # --- New patterns (negation + technical) ---
            "thiáº¿t bá»‹ khÃ´ng rung nhÆ°ng bá»‘c mÃ¹i khÃ©t chÃ¡y dá»¯ dá»™i kÃ¨m khÃ³i Ä‘en",
            "cuá»™n dÃ¢y stator bá»‹ ngáº¯n máº¡ch bá»‘c khÃ³i mÃ¹i nhá»±a nÃ³ng cháº£y",
            "motor phÃ¡t tia lá»­a bÃªn trong mÃ¹i chÃ¡y khÃ©t ná»“ng náº·c lan kháº¯p phÃ²ng",
            "lá»›p cÃ¡ch Ä‘iá»‡n cuá»™n dÃ¢y bá»‹ cháº£y motor bá»‘c khÃ³i tráº¯ng dá»«ng quay",
            "phÃ¡t hiá»‡n vÃ¡ng chÃ¡y Ä‘en trÃªn cuá»™n dÃ¢y khi thÃ¡o motor kiá»ƒm tra",
            "motor báº¥t ngá» dá»«ng kÃ¨m mÃ¹i chÃ¡y kiá»ƒm tra tháº¥y dÃ¢y quáº¥n Ä‘á»©t chÃ¡y",
            "khÃ´ng rung khÃ´ng á»“n nhÆ°ng mÃ¹i khÃ©t dá»¯ dá»™i bá»‘c khÃ³i tá»« motor",
            "cuá»™n dÃ¢y motor bá»‹ Ä‘oáº£n máº¡ch chÃ¡y Ä‘en mÃ¹i khÃ©t bá»‘c khÃ³i náº·ng",
            "motor chÃ¡y cuá»™n dÃ¢y stator bá»‹ ngáº¯n máº¡ch cháº­p giá»¯a cÃ¡c pha",
            "mÃ¹i chÃ¡y khÃ©t náº·ng ná» motor dá»«ng Ä‘á»™t ngá»™t bá»‘c khÃ³i Ä‘en",
        ],
        "severity_base": 0.9,
        "description": "QuÃ¡ nhiá»‡t káº¿t há»£p mÃ¹i chÃ¡y â€” chÃ¡y cuá»™n dÃ¢y hoáº·c chÃ¡y motor",
    },
    "Sá»± cá»‘ Ä‘iá»‡n": {
        "samples": [
            "dÃ²ng Ä‘iá»‡n tÄƒng Ä‘á»™t ngá»™t cháº­p máº¡ch phÃ³ng Ä‘iá»‡n",
            "tia lá»­a Ä‘iá»‡n rÃ² Ä‘iá»‡n cháº­p Ä‘iá»‡n",
            "dÃ²ng Ä‘iá»‡n dao Ä‘á»™ng báº¥t thÆ°á»ng quÃ¡ táº£i chÃ¡y cáº§u chÃ¬",
            "máº¥t pha lá»‡ch pha sá»¥t Ã¡p dÃ²ng Ä‘iá»‡n báº¥t thÆ°á»ng",
            "Ä‘iá»‡n giáº­t rÃ² Ä‘iá»‡n nguy hiá»ƒm cháº­p máº¡ch",
            "cháº­p Ä‘iá»‡n chÃ¡y cáº§u chÃ¬ sá»¥t Ã¡p nghiÃªm trá»ng",
            "rÃ² Ä‘iá»‡n ra vá» thiáº¿t bá»‹ cháº¡m vÃ o bá»‹ giáº­t",
            "cháº­p máº¡ch tá»§ Ä‘iá»‡n Ä‘iá»u khiá»ƒn cáº§u chÃ¬ ná»•",
            "tia lá»­a Ä‘iá»‡n phÃ³ng ra tá»« Ä‘áº§u ná»‘i nguy hiá»ƒm",
            "dÃ²ng Ä‘iá»‡n tÄƒng Ä‘á»™t ngá»™t vÆ°á»£t giá»›i háº¡n cho phÃ©p",
            "sá»¥t Ã¡p tráº§m trá»ng thiáº¿t bá»‹ cháº¡y yáº¿u Ä‘iá»‡n khÃ´ng á»•n",
            "lá»‡ch pha gÃ¢y rung motor dÃ²ng Ä‘iá»‡n báº¥t thÆ°á»ng",
            "rÃ² Ä‘iá»‡n nghiÃªm trá»ng vá» mÃ¡y Ä‘iá»‡n giáº­t",
            "relay báº£o vá»‡ nháº£y ngáº¯t liÃªn tá»¥c cháº­p Ä‘iá»‡n",
            "dÃ²ng Ä‘iá»‡n quÃ¡ táº£i gÃ¢y chÃ¡y cáº§u chÃ¬ báº£o vá»‡",
            # --- New patterns (negation + technical terms) ---
            "thiáº¿t bá»‹ khÃ´ng nÃ³ng khÃ´ng rung nhÆ°ng dÃ²ng Ä‘iá»‡n dao Ä‘á»™ng báº¥t thÆ°á»ng liÃªn tá»¥c",
            "MCB báº£o vá»‡ nháº£y liÃªn tá»¥c khi khá»Ÿi Ä‘á»™ng motor nghi ngá» cháº¡m mass",
            "dÃ¢y cÃ¡p nguá»“n bá»‹ cháº£y vá» nhá»±a do quÃ¡ dÃ²ng Ä‘áº§u ná»‘i bá»‹ Ä‘en oxy hÃ³a",
            "biáº¿n táº§n bÃ¡o lá»—i quÃ¡ dÃ²ng pha R motor khá»Ÿi Ä‘á»™ng rá»“i tá»± ngáº¯t",
            "aptomat chá»‘ng rÃ² nháº£y khi motor cháº¡y nghi ngá» rÃ² Ä‘iá»‡n ra thÃ¢n vá»",
            "motor bá»‹ máº¥t pha gÃ¢y rung báº¥t thÆ°á»ng cáº§u chÃ¬ má»™t pha bá»‹ Ä‘á»©t",
            "relay nhiá»‡t tÃ¡c Ä‘á»™ng ngáº¯t motor liÃªn tá»¥c dÃ¹ táº£i khÃ´ng Ä‘á»•i",
            "Ä‘áº§u ná»‘i cÃ¡p bá»‹ há»“ quang Ä‘iá»‡n mÃ¹i ozone tia lá»­a phÃ³ng ra",
            "khÃ´ng nÃ³ng khÃ´ng rung chá»‰ cÃ³ dÃ²ng Ä‘iá»‡n báº¥t á»•n MCB nháº£y liÃªn tá»¥c",
            "biáº¿n táº§n bÃ¡o lá»—i sá»± cá»‘ Ä‘iá»‡n motor khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c",
        ],
        "severity_base": 0.85,
        "description": "Váº¥n Ä‘á» há»‡ thá»‘ng Ä‘iá»‡n â€” cháº­p, rÃ², quÃ¡ táº£i",
    },
    "QuÃ¡ táº£i cÆ¡ khÃ­": {
        "samples": [
            "nÃ³ng báº¥t thÆ°á»ng kÃ¨m rung máº¡nh quÃ¡ táº£i",
            "nhiá»‡t Ä‘á»™ cao rung Ä‘á»™ng máº¡nh thiáº¿t bá»‹ quÃ¡ táº£i",
            "quÃ¡ nÃ³ng rung láº¯c máº¡nh dÃ¢y Ä‘ai cÄƒng quÃ¡ táº£i",
            "motor nÃ³ng rung máº¡nh cháº¡y cháº­m cÃ´ng suáº¥t giáº£m",
            "thiáº¿t bá»‹ quÃ¡ táº£i nÃ³ng rung giáº­t káº¹t",
            "motor nÃ³ng rung máº¡nh cháº¡y yáº¿u quÃ¡ táº£i liÃªn tá»¥c",
            "thiáº¿t bá»‹ quÃ¡ táº£i nÃ³ng kÃ¨m rung láº¯c máº¡nh giáº­t cá»¥c",
            "nÃ³ng báº¥t thÆ°á»ng kÃ¨m rung do cháº¡y quÃ¡ cÃ´ng suáº¥t",
            "nÃ³ng rung máº¡nh dÃ¢y Ä‘ai cÄƒng quÃ¡ má»©c do quÃ¡ táº£i",
            "quÃ¡ táº£i liÃªn tá»¥c gÃ¢y nÃ³ng motor rung máº¡nh giáº£m cÃ´ng suáº¥t",
            "mÃ¡y nÃ³ng cháº¡y cháº­m háº³n do quÃ¡ táº£i cÆ¡ khÃ­ nghiÃªm trá»ng",
            "rung máº¡nh kÃ¨m nÃ³ng thiáº¿t bá»‹ bá»‹ káº¹t do quÃ¡ táº£i",
            "motor nÃ³ng ran rung láº¯c táº£i vÆ°á»£t thÃ´ng sá»‘ thiáº¿t káº¿",
            "mÃ¡y nÃ©n quÃ¡ táº£i nÃ³ng rung máº¡nh cÃ´ng suáº¥t sá»¥t giáº£m",
            "táº£i quÃ¡ náº·ng khiáº¿n motor nÃ³ng rung cháº¡y cháº­m láº¡i",
            # --- New patterns (negation + cross-symptom) ---
            "motor khÃ´ng khÃ©t khÃ´ng chÃ¡y nhÆ°ng nÃ³ng kÃ¨m rung do cháº¡y vÆ°á»£t cÃ´ng suáº¥t",
            "thiáº¿t bá»‹ káº¹t táº£i náº·ng ampe káº¿ chá»‰ vÆ°á»£t Ä‘á»‹nh má»©c motor rÃ­t cháº¡y cháº­m",
            "bÄƒng táº£i bá»‹ quÃ¡ táº£i do hÃ ng hÃ³a cháº¥t nhiá»u gÃ¢y motor cÄƒng dÃ¢y Ä‘ai",
            "motor kÃ©o táº£i quÃ¡ náº·ng dÃ¢y Ä‘ai trÆ°á»£t liÃªn tá»¥c phÃ¡t mÃ¹i cao su",
            "mÃ¡y bÆ¡m bá»‹ quÃ¡ táº£i do van Ä‘áº§u ra Ä‘Ã³ng Ã¡p suáº¥t tÄƒng motor rung giáº­t",
            "cÃ´ng suáº¥t yÃªu cáº§u vÆ°á»£t xa thÃ´ng sá»‘ thiáº¿t káº¿ motor nÃ³ng kÃ¨m tiáº¿ng rÃ­t",
            "táº£i cÆ¡ khÃ­ quÃ¡ lá»›n khiáº¿n motor cháº¡y cháº­m háº³n dÃ²ng Ä‘iá»‡n tÄƒng gáº¥p Ä‘Ã´i",
            "khÃ´ng chÃ¡y khÃ´ng khÃ©t chá»‰ nÃ³ng rung do kÃ©o táº£i vÆ°á»£t cÃ´ng suáº¥t mÃ¡y",
            "quÃ¡ táº£i lÃ m motor nÃ³ng rung máº¡nh ampe tÄƒng cao dÃ¢y Ä‘ai trÆ°á»£t",
            "thiáº¿t bá»‹ káº¹t do táº£i quÃ¡ lá»›n nÃ³ng rung giáº­t motor cháº¡y cháº­m",
        ],
        "severity_base": 0.8,
        "description": "QuÃ¡ nhiá»‡t + rung Ä‘á»™ng â€” thiáº¿t bá»‹ bá»‹ quÃ¡ táº£i",
    },
    "RÃ² rá»‰ há»‡ thá»‘ng": {
        "samples": [
            "rÃ² rá»‰ dáº§u cháº£y dáº§u dáº§u loang",
            "rÃ² rá»‰ nÆ°á»›c xÃ¬ hÆ¡i cháº£y nÆ°á»›c",
            "gioÄƒng há»ng rÃ² rá»‰ rá»‰ dáº§u trÃ n dáº§u",
            "phá»›t há»ng rÃ² rá»‰ dáº§u Ã¡p suáº¥t giáº£m",
            "seal há»ng rÃ² rá»‰ nÆ°á»›c cháº£y trÃ n",
            "dáº§u cháº£y trÃ n ra ná»n gioÄƒng bá»‹ rÃ¡ch há»ng náº·ng",
            "rÃ² rá»‰ dáº§u thá»§y lá»±c tá»« á»‘ng ná»‘i dáº§u loang kháº¯p nÆ¡i",
            "phá»›t bÆ¡m há»ng gÃ¢y rÃ² rá»‰ nÆ°á»›c liÃªn tá»¥c",
            "xÃ¬ hÆ¡i tá»« van Ã¡p suáº¥t giáº£m do rÃ² rá»‰ khÃ­",
            "seal bá»‹ mÃ²n gÃ¢y rá»‰ dáº§u tá»« trá»¥c bÆ¡m",
            "rÃ² rá»‰ nÆ°á»›c lÃ m mÃ¡t tá»« Ä‘Æ°á»ng á»‘ng cháº£y nÆ°á»›c liÃªn tá»¥c",
            "dáº§u rÃ² rá»‰ tá»« há»™p sá»‘ váº¿t dáº§u loang trÃªn sÃ n",
            "bÆ¡m thá»§y lá»±c rÃ² dáº§u tá»« phá»›t trá»¥c Ã¡p suáº¥t sá»¥t",
            "rá»‰ dáº§u nhá» giá»t liÃªn tá»¥c tá»« Ä‘Ã¡y thiáº¿t bá»‹",
            "xÃ¬ khÃ­ tá»« Ä‘Æ°á»ng á»‘ng Ã¡p suáº¥t cao rÃ² rá»‰ nghiÃªm trá»ng",
            # --- New patterns (negation + technical) ---
            "khÃ´ng nÃ³ng khÃ´ng rung nhÆ°ng phÃ¡t hiá»‡n vÅ©ng dáº§u dÆ°á»›i Ä‘Ã¡y mÃ¡y nÃ©n",
            "á»‘ng dáº«n dáº§u thá»§y lá»±c bá»‹ ráº¡n ná»©t gÃ¢y rÃ² rá»‰ nhá» giá»t liÃªn tá»¥c",
            "van xáº£ an toÃ n bá»‹ xÃ¬ hÆ¡i liÃªn tá»¥c Ã¡p suáº¥t bÃ¬nh chá»©a giáº£m dáº§n",
            "máº·t bÃ­ch Ä‘Æ°á»ng á»‘ng bá»‹ cháº£y nÆ°á»›c táº¡i vá»‹ trÃ­ gioÄƒng láº¯p Ä‘áº·t",
            "cylinder thá»§y lá»±c bá»‹ rá»‰ dáº§u tá»« vá»‹ trÃ­ phá»›t trÆ°á»£t hÃ nh trÃ¬nh khÃ´ng Ä‘á»§",
            "há»‡ thá»‘ng khÃ­ nÃ©n bá»‹ xÃ¬ hÆ¡i nhiá»u vá»‹ trÃ­ compressor cháº¡y liÃªn tá»¥c bÃ¹ Ã¡p",
            "bá»ƒ chá»©a dáº§u giáº£m má»©c bÃ¡o Ä‘á»™ng dÃ¹ khÃ´ng sá»­ dá»¥ng nghi rÃ² rá»‰ Ä‘Æ°á»ng á»‘ng",
            "khÃ´ng á»“n khÃ´ng nÃ³ng chá»‰ phÃ¡t hiá»‡n váº¿t dáº§u rÃ² rá»‰ dÆ°á»›i mÃ¡y",
            "phá»›t trá»¥c chÃ­nh bá»‹ há»ng gÃ¢y rÃ² dáº§u thá»§y lá»±c náº·ng",
            "rÃ² rá»‰ khÃ­ nÃ©n tá»« khá»›p ná»‘i á»‘ng Ã¡p suáº¥t giáº£m dáº§n liÃªn tá»¥c",
        ],
        "severity_base": 0.5,
        "description": "RÃ² rá»‰ dáº§u, nÆ°á»›c, hoáº·c khÃ­ trong há»‡ thá»‘ng",
    },
    "HÆ° há»ng cÆ¡ khÃ­": {
        "samples": [
            "ná»©t vá»¡ gÃ£y biáº¿n dáº¡ng cong vÃªnh",
            "mÃ²n nhiá»u Äƒn mÃ²n gá»‰ sÃ©t han gá»‰",
            "Ä‘á»©t dÃ¢y Ä‘ai dÃ¢y Ä‘ai mÃ²n tuá»™t",
            "lá»ng bu lÃ´ng lung lay trá»¥c lá»‡ch trá»¥c cong",
            "báº¡c Ä‘áº¡n há»ng vÃ²ng bi há»ng mÃ²n nhiá»u",
            "trá»¥c bá»‹ cong vÃªnh bu lÃ´ng lá»ng nhiá»u chá»—",
            "dÃ¢y Ä‘ai bá»‹ Ä‘á»©t rÃ¡ch khÃ´ng truyá»n Ä‘á»™ng Ä‘Æ°á»£c",
            "bÃ¡nh rÄƒng bá»‹ mÃ²n nhiá»u Äƒn khá»›p khÃ´ng Ä‘á»u",
            "gá»‰ sÃ©t náº·ng bá» máº·t kim loáº¡i han gá»‰ Äƒn mÃ²n",
            "thÃ¢n mÃ¡y bá»‹ ná»©t vá»¡ biáº¿n dáº¡ng nghiÃªm trá»ng",
            "bu lÃ´ng cá»‘ Ä‘á»‹nh bá»‹ lá»ng thiáº¿t bá»‹ lung lay",
            "trá»¥c truyá»n Ä‘á»™ng bá»‹ cong lá»‡ch tÃ¢m nghiÃªm trá»ng",
            "chi tiáº¿t mÃ¡y bá»‹ gÃ£y ná»©t do má»i váº­t liá»‡u",
            "khá»›p ná»‘i bá»‹ mÃ²n xÆ°á»›c Äƒn mÃ²n bá» máº·t náº·ng",
            "vá» thiáº¿t bá»‹ bá»‹ ná»©t vá»¡ do va Ä‘áº­p cÆ¡ khÃ­",
            # --- New patterns (negation + technical) ---
            "khÃ´ng á»“n khÃ´ng nÃ³ng nhÆ°ng kiá»ƒm tra tháº¥y ná»©t thÃ¢n vá» mÃ¡y bÆ¡m",
            "bÃ¡nh rÄƒng há»™p sá»‘ bá»‹ sá»©t máº» nhiá»u rÄƒng cháº¡y giáº­t cá»¥c khi vÃ o táº£i",
            "chá»‘t khá»›p ná»‘i giá»¯a motor vÃ  bÆ¡m bá»‹ cáº¯t Ä‘á»©t do má»i kim loáº¡i",
            "cÃ¡nh quáº¡t bá»‹ ná»©t gÃ£y máº¥t cÃ¢n báº±ng gÃ¢y rung khi cháº¡y tá»‘c Ä‘á»™ cao",
            "trá»¥c truyá»n Ä‘á»™ng bá»‹ xoáº¯n biáº¿n dáº¡ng sau sá»± cá»‘ káº¹t táº£i Ä‘á»™t ngá»™t",
            "Ä‘áº¿ láº¯p thiáº¿t bá»‹ bá»‹ ná»©t foundation bu lÃ´ng neo bá»‹ nhá»• gÃ¢y lá»‡ch trá»¥c",
            "khá»›p ná»‘i má»m bá»‹ rÃ¡ch vá»¡ cao su Ä‘á»‡m khÃ´ng truyá»n lá»±c hiá»‡u quáº£",
            "khÃ´ng nÃ³ng khÃ´ng rung nhÆ°ng phÃ¡t hiá»‡n ná»©t vá»¡ cÆ¡ khÃ­ khi kiá»ƒm tra",
            "bu lÃ´ng cá»‘ Ä‘á»‹nh lá»ng thiáº¿t bá»‹ lung lay khi cháº¡y hÆ° há»ng cÆ¡ khÃ­",
            "phÃ¡t hiá»‡n gÃ£y ná»©t chi tiáº¿t mÃ¡y do má»i váº­t liá»‡u sau kiá»ƒm tra",
        ],
        "severity_base": 0.6,
        "description": "HÆ° há»ng cÃ¡c bá»™ pháº­n cÆ¡ khÃ­",
    },
    "Ã‚m thanh báº¥t thÆ°á»ng": {
        "samples": [
            "tiáº¿ng á»“n láº¡ tiáº¿ng kÃªu báº¥t thÆ°á»ng",
            "á»“n lá»›n tiáº¿ng rÃ­t tiáº¿ng cá» sÃ¡t",
            "tiáº¿ng va Ä‘áº­p tiáº¿ng ná»• gáº§m",
            "tiáº¿ng káº¹t tiáº¿ng Ã¹ tiáº¿ng láº¡",
            "kÃªu to kÃªu lá»›n tiáº¿ng cáº¡ch cáº¡ch",
            "tiáº¿ng á»“n báº¥t thÆ°á»ng kÃªu to liÃªn tá»¥c tá»« motor",
            "tiáº¿ng rÃ­t cao phÃ¡t ra tá»« thiáº¿t bá»‹ khi váº­n hÃ nh",
            "tiáº¿ng va Ä‘áº­p lá»›n bÃªn trong mÃ¡y á»“n báº¥t thÆ°á»ng",
            "tiáº¿ng Ã¹ to liÃªn tá»¥c tá»« motor chÃ­nh",
            "thiáº¿t bá»‹ phÃ¡t tiáº¿ng káº¹t nghiáº¿n khi hoáº¡t Ä‘á»™ng",
            "Ã¢m thanh láº¡ phÃ¡t ra liÃªn tá»¥c á»“n hÆ¡n bÃ¬nh thÆ°á»ng",
            "tiáº¿ng ná»• nhá» lÃ¡ch tÃ¡ch liÃªn tá»¥c tá»« thiáº¿t bá»‹",
            "phÃ¡t ra tiáº¿ng cá» sÃ¡t láº¡ khi motor quay",
            "tiáº¿ng á»“n lá»›n báº¥t thÆ°á»ng khi thiáº¿t bá»‹ khá»Ÿi Ä‘á»™ng",
            "tiáº¿ng kÃªu báº¥t thÆ°á»ng nghe rÃµ tá»« xa mÃ¡y cháº¡y",
            # --- New patterns (negation + varied) ---
            "thiáº¿t bá»‹ khÃ´ng nÃ³ng khÃ´ng rung nhÆ°ng phÃ¡t ra tiáº¿ng Ã¹ vÃ¹ liÃªn tá»¥c láº¡",
            "nghe tiáº¿ng tÃ¡ch tÃ¡ch Ä‘á»u Ä‘áº·n bÃªn trong há»™p sá»‘ khi motor cháº¡y",
            "motor phÃ¡t ra tiáº¿ng huÃ½t sÃ¡o cao táº§n khi tÄƒng tá»‘c báº¥t thÆ°á»ng",
            "tiáº¿ng gÃµ lá»›n nhá»‹p Ä‘á»u phÃ¡t ra tá»« Ä‘áº§u piston mÃ¡y nÃ©n má»—i khi nÃ©n",
            "quáº¡t hÃºt phÃ¡t ra tiáº¿ng rung rá»n láº¡ khi tá»‘c Ä‘á»™ giÃ³ thay Ä‘á»•i",
            "tiáº¿ng láº¡ch xáº¡ch liÃªn tá»¥c tá»« bÃªn trong motor dÃ¹ khÃ´ng táº£i",
            "Ã¢m vang báº¥t thÆ°á»ng khi cháº¡y khÃ´ng táº£i táº¯t mÃ¡y thÃ¬ háº¿t tiáº¿ng",
            "khÃ´ng nÃ³ng khÃ´ng khÃ©t nhÆ°ng tiáº¿ng á»“n báº¥t thÆ°á»ng phÃ¡t ra tá»« motor",
            "tiáº¿ng rá»n láº¡ phÃ¡t ra tá»« thiáº¿t bá»‹ khi váº­n hÃ nh Ã¢m thanh báº¥t thÆ°á»ng",
            "thiáº¿t bá»‹ phÃ¡t tiáº¿ng á»“n láº¡ nghe rÃµ khi cháº¡y khÃ´ng táº£i",
        ],
        "severity_base": 0.5,
        "description": "PhÃ¡t hiá»‡n Ã¢m thanh báº¥t thÆ°á»ng tá»« thiáº¿t bá»‹",
    },
    "Giáº£m hiá»‡u suáº¥t": {
        "samples": [
            "cháº¡y cháº­m yáº¿u cÃ´ng suáº¥t giáº£m",
            "khÃ´ng khá»Ÿi Ä‘á»™ng khÃ´ng cháº¡y dá»«ng Ä‘á»™t ngá»™t",
            "táº¯t Ä‘á»™t ngá»™t cháº­p chá»n khÃ´ng á»•n Ä‘á»‹nh",
            "hoáº¡t Ä‘á»™ng cháº­m káº¹t treo mÃ¡y",
            "quÃ¡ tá»‘c hiá»‡u suáº¥t tháº¥p nÄƒng suáº¥t giáº£m",
            "mÃ¡y cháº­p chá»n táº¯t báº­t liÃªn tá»¥c khÃ´ng á»•n Ä‘á»‹nh",
            "thiáº¿t bá»‹ cháº¡y cháº­m háº³n cÃ´ng suáº¥t sá»¥t giáº£m rÃµ rá»‡t",
            "motor khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c báº¥m nÃºt khÃ´ng pháº£n há»“i",
            "mÃ¡y dá»«ng Ä‘á»™t ngá»™t giá»¯a chá»«ng khi Ä‘ang váº­n hÃ nh",
            "thiáº¿t bá»‹ hoáº¡t Ä‘á»™ng yáº¿u khÃ´ng Ä‘áº¡t cÃ´ng suáº¥t thiáº¿t káº¿",
            "motor cháº¡y cháº­m hÆ¡n bÃ¬nh thÆ°á»ng nÄƒng suáº¥t giáº£m",
            "thiáº¿t bá»‹ táº¯t Ä‘á»™t ngá»™t khÃ´ng khá»Ÿi Ä‘á»™ng láº¡i Ä‘Æ°á»£c",
            "hiá»‡u suáº¥t giáº£m rÃµ rá»‡t mÃ¡y cháº¡y yáº¿u háº³n",
            "thiáº¿t bá»‹ khÃ´ng Ä‘áº¡t tá»‘c Ä‘á»™ yÃªu cáº§u cháº¡y cháº­m",
            "cÃ´ng suáº¥t Ä‘áº§u ra giáº£m máº¡nh so vá»›i thÃ´ng sá»‘ thiáº¿t káº¿",
            # --- New patterns (negation + operational) ---
            "khÃ´ng á»“n khÃ´ng nÃ³ng nhÆ°ng mÃ¡y cháº¡y ngÃ y cÃ ng cháº­m cÃ´ng suáº¥t sá»¥t rÃµ rá»‡t",
            "bÆ¡m bÆ¡m khÃ´ng Ä‘á»§ lÆ°u lÆ°á»£ng dÃ¹ motor cháº¡y Ä‘á»§ vÃ²ng tua nghi cÃ¡nh bÆ¡m mÃ²n",
            "motor khá»Ÿi Ä‘á»™ng lÃ¢u hÆ¡n bÃ¬nh thÆ°á»ng máº¥t gáº§n 30 giÃ¢y má»›i Ä‘áº¡t vÃ²ng quay",
            "thiáº¿t bá»‹ tá»± ngáº¯t giá»¯a chá»«ng rá»“i khá»Ÿi Ä‘á»™ng láº¡i liÃªn tá»¥c khÃ´ng á»•n Ä‘á»‹nh",
            "nÄƒng suáº¥t sáº£n xuáº¥t giáº£m 30 pháº§n trÄƒm so vá»›i thÃ¡ng trÆ°á»›c dÃ¹ cÃ¹ng táº£i",
            "quáº¡t quay cháº­m hÆ¡n bÃ¬nh thÆ°á»ng dÃ¹ Ä‘iá»‡n Ã¡p cung cáº¥p Ä‘Ãºng thÃ´ng sá»‘",
            "motor cháº¡y nhÆ°ng moment xoáº¯n yáº¿u khÃ´ng Ä‘á»§ kÃ©o táº£i nhÆ° thiáº¿t káº¿",
            "khÃ´ng nÃ³ng khÃ´ng rung nhÆ°ng cÃ´ng suáº¥t Ä‘áº§u ra giáº£m rÃµ rá»‡t hiá»‡u suáº¥t tháº¥p",
            "thiáº¿t bá»‹ cháº¡y yáº¿u háº³n hiá»‡u suáº¥t giáº£m dáº§n theo thá»i gian",
            "mÃ¡y hoáº¡t Ä‘á»™ng nhÆ°ng nÄƒng suáº¥t tháº¥p khÃ´ng Ä‘áº¡t yÃªu cáº§u sáº£n xuáº¥t",
        ],
        "severity_base": 0.55,
        "description": "Thiáº¿t bá»‹ hoáº¡t Ä‘á»™ng khÃ´ng Ä‘áº¡t hiá»‡u suáº¥t mong Ä‘á»£i",
    },
}


# ============================================================
# 3. SYMPTOM KEYWORD DATABASE (for keyword extraction display)
# ============================================================

SYMPTOM_KEYWORDS = {
    "Nhiá»‡t Ä‘á»™": [
        "nÃ³ng báº¥t thÆ°á»ng", "nÃ³ng cháº£y", "nhiá»‡t Ä‘á»™ cao", "nhiá»‡t Ä‘á»™ ráº¥t cao",
        "quÃ¡ nhiá»‡t", "quÃ¡ nÃ³ng", "nÃ³ng", "nÃ³ng ran", "tá»a nhiá»‡t",
        "chÃ¡y tay", "bá»ng tay", "khÃ³i", "bá»‘c khÃ³i", "hÆ¡i nÃ³ng",
    ],
    "Rung Ä‘á»™ng": [
        "rung máº¡nh", "rung báº¥t thÆ°á»ng", "rung láº¯c", "rung láº¯c máº¡nh",
        "rung", "rung nháº¹", "rung liÃªn tá»¥c", "dao Ä‘á»™ng máº¡nh",
        "giáº­t", "giáº­t cá»¥c", "lung lay", "xÃ³c",
    ],
    "Ã‚m thanh": [
        "tiáº¿ng kim loáº¡i va cháº¡m", "tiáº¿ng kim loáº¡i", "tiáº¿ng kÃªu láº¡",
        "tiáº¿ng kÃªu báº¥t thÆ°á»ng", "á»“n báº¥t thÆ°á»ng", "á»“n lá»›n", "tiáº¿ng á»“n láº¡",
        "tiáº¿ng rÃ­t", "tiáº¿ng rÃ­t cao", "tiáº¿ng cá» sÃ¡t", "tiáº¿ng va Ä‘áº­p",
        "tiáº¿ng Ã¹", "tiáº¿ng láº¡", "tiáº¿ng káº¹t", "tiáº¿ng ná»•", "ná»•",
        "tiáº¿ng cáº¡ch cáº¡ch", "tiáº¿ng lÃ¡ch cÃ¡ch", "gáº§m",
    ],
    "MÃ¹i": [
        "mÃ¹i khÃ©t", "mÃ¹i chÃ¡y", "khÃ©t", "mÃ¹i dáº§u chÃ¡y", "mÃ¹i dáº§u",
        "mÃ¹i nhá»›t chÃ¡y", "mÃ¹i cao su chÃ¡y", "mÃ¹i nhá»±a chÃ¡y",
        "mÃ¹i láº¡", "mÃ¹i hÃ´i", "mÃ¹i háº¯c", "bá»‘c mÃ¹i", "chÃ¡y khÃ©t",
    ],
    "Äiá»‡n": [
        "dÃ²ng Ä‘iá»‡n tÄƒng Ä‘á»™t ngá»™t", "dÃ²ng Ä‘iá»‡n tÄƒng", "dÃ²ng Ä‘iá»‡n dao Ä‘á»™ng",
        "dÃ²ng Ä‘iá»‡n báº¥t thÆ°á»ng", "cháº­p Ä‘iá»‡n", "Ä‘Ã¡nh lá»­a", "phÃ³ng Ä‘iá»‡n",
        "tia lá»­a", "tia lá»­a Ä‘iá»‡n", "Ä‘iá»‡n giáº­t", "rÃ² Ä‘iá»‡n", "cháº­p máº¡ch",
        "chÃ¡y cáº§u chÃ¬", "quÃ¡ táº£i", "sá»¥t Ã¡p", "máº¥t pha", "lá»‡ch pha",
    ],
    "RÃ² rá»‰": [
        "rÃ² rá»‰ dáº§u", "rÃ² rá»‰ nÆ°á»›c", "rÃ² rá»‰", "cháº£y dáº§u", "cháº£y nÆ°á»›c",
        "rá»‰ dáº§u", "dáº§u loang", "xÃ¬", "xÃ¬ hÆ¡i", "trÃ n dáº§u",
    ],
    "CÆ¡ khÃ­": [
        "gÃ£y", "ná»©t", "vá»¡", "mÃ²n", "mÃ²n nhiá»u", "Äƒn mÃ²n", "gá»‰ sÃ©t",
        "han gá»‰", "biáº¿n dáº¡ng", "cong vÃªnh", "lá»ng", "lá»ng bu lÃ´ng",
        "tuá»™t", "Ä‘á»©t dÃ¢y Ä‘ai", "dÃ¢y Ä‘ai mÃ²n", "báº¡c Ä‘áº¡n há»ng",
        "báº¡c Ä‘áº¡n", "vÃ²ng bi", "vÃ²ng bi há»ng", "trá»¥c bá»‹ cong", "trá»¥c lá»‡ch",
    ],
    "Hiá»‡u suáº¥t": [
        "cháº¡y cháº­m", "yáº¿u", "cÃ´ng suáº¥t giáº£m", "khÃ´ng khá»Ÿi Ä‘á»™ng",
        "khÃ´ng cháº¡y", "dá»«ng Ä‘á»™t ngá»™t", "táº¯t Ä‘á»™t ngá»™t", "cháº­p chá»n",
        "khÃ´ng á»•n Ä‘á»‹nh", "hoáº¡t Ä‘á»™ng cháº­m", "káº¹t", "treo", "quÃ¡ tá»‘c",
    ],
}

# Vietnamese negation words
NEGATION_WORDS = [
    "khÃ´ng cÃ³", "khÃ´ng bá»‹", "khÃ´ng tháº¥y", "khÃ´ng nghe",
    "khÃ´ng phÃ¡t hiá»‡n", "khÃ´ng cÃ²n", "khÃ´ng há»",
    "chÆ°a cÃ³", "chÆ°a bá»‹", "chÆ°a tháº¥y", "chÆ°a phÃ¡t hiá»‡n",
    "háº¿t", "Ä‘Ã£ háº¿t", "khÃ´ng", "chÆ°a",
]


# ============================================================
# 4. RECOMMENDATION DATABASE
# ============================================================

RECOMMENDATIONS_DB = {
    "ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor": [
        "ğŸš¨ Dá»ªNG THIáº¾T Bá»Š NGAY Láº¬P Tá»¨C",
        "Ngáº¯t nguá»“n Ä‘iá»‡n vÃ  Ä‘áº£m báº£o an toÃ n khu vá»±c",
        "Kiá»ƒm tra cÃ¡ch Ä‘iá»‡n cuá»™n dÃ¢y (megger test)",
        "Kiá»ƒm tra há»‡ thá»‘ng lÃ m mÃ¡t vÃ  quáº¡t giÃ³",
        "ÄÃ¡nh giÃ¡ láº¡i Ä‘iá»u kiá»‡n táº£i â€” cÃ³ thá»ƒ quÃ¡ táº£i",
        "LiÃªn há»‡ ká»¹ sÆ° Ä‘iá»‡n Ä‘á»ƒ kiá»ƒm tra chuyÃªn sÃ¢u",
    ],
    "Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi": [
        "ğŸš¨ Dá»ªNG THIáº¾T Bá»Š Ä‘á»ƒ trÃ¡nh hÆ° há»ng thÃªm",
        "Kiá»ƒm tra báº¡c Ä‘áº¡n / vÃ²ng bi â€” thay tháº¿ náº¿u cáº§n",
        "Kiá»ƒm tra há»‡ thá»‘ng bÃ´i trÆ¡n â€” bá»• sung má»¡ bÃ´i trÆ¡n",
        "Kiá»ƒm tra Ä‘á»™ Ä‘á»“ng trá»¥c (alignment) cÃ¡c khá»›p ná»‘i",
        "Kiá»ƒm tra cÃ¢n báº±ng Ä‘á»™ng rotor",
    ],
    "QuÃ¡ táº£i cÆ¡ khÃ­": [
        "ğŸš¨ GIáº¢M Táº¢I NGAY hoáº·c dá»«ng thiáº¿t bá»‹",
        "Kiá»ƒm tra Ä‘iá»u kiá»‡n táº£i hiá»‡n táº¡i so vá»›i thÃ´ng sá»‘ thiáº¿t káº¿",
        "Kiá»ƒm tra há»‡ thá»‘ng truyá»n Ä‘á»™ng (dÃ¢y Ä‘ai, khá»›p ná»‘i, há»™p sá»‘)",
        "Kiá»ƒm tra há»‡ thá»‘ng lÃ m mÃ¡t",
        "ÄÃ¡nh giÃ¡ láº¡i quy trÃ¬nh váº­n hÃ nh",
    ],
    "Sá»± cá»‘ Ä‘iá»‡n": [
        "ğŸš¨ NGáº®T NGUá»’N ÄIá»†N NGAY",
        "Kiá»ƒm tra cÃ¡ch Ä‘iá»‡n toÃ n bá»™ há»‡ thá»‘ng",
        "Kiá»ƒm tra Ä‘iá»‡n Ã¡p, dÃ²ng Ä‘iá»‡n, há»‡ sá»‘ cÃ´ng suáº¥t",
        "Kiá»ƒm tra tá»§ Ä‘iá»‡n, CB, contactor, relay báº£o vá»‡",
        "Kiá»ƒm tra tiáº¿p Ä‘á»‹a vÃ  há»‡ thá»‘ng báº£o vá»‡",
        "LiÃªn há»‡ ká»¹ sÆ° Ä‘iá»‡n chuyÃªn trÃ¡ch",
    ],
    "QuÃ¡ nhiá»‡t": [
        "Giáº£m táº£i hoáº·c dá»«ng thiáº¿t bá»‹ Ä‘á»ƒ háº¡ nhiá»‡t",
        "Kiá»ƒm tra há»‡ thá»‘ng lÃ m mÃ¡t (quáº¡t, nÆ°á»›c, dáº§u)",
        "Kiá»ƒm tra Ä‘iá»u kiá»‡n mÃ´i trÆ°á»ng (thÃ´ng giÃ³, nhiá»‡t Ä‘á»™ xung quanh)",
        "Kiá»ƒm tra há»‡ thá»‘ng bÃ´i trÆ¡n",
        "Theo dÃµi nhiá»‡t Ä‘á»™ báº±ng camera nhiá»‡t náº¿u cÃ³",
    ],
    "RÃ² rá»‰ há»‡ thá»‘ng": [
        "XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ rÃ² rá»‰ chÃ­nh xÃ¡c",
        "Kiá»ƒm tra gioÄƒng, phá»›t, seal â€” thay tháº¿ náº¿u há»ng",
        "Kiá»ƒm tra Ã¡p suáº¥t há»‡ thá»‘ng",
        "Bá»• sung dáº§u/nÆ°á»›c náº¿u thiáº¿u",
        "LÃªn káº¿ hoáº¡ch báº£o trÃ¬ thay tháº¿ seal",
    ],
    "HÆ° há»ng cÆ¡ khÃ­": [
        "Kiá»ƒm tra chi tiáº¿t bá»™ pháº­n bá»‹ hÆ° há»ng",
        "ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ hÆ° há»ng â€” sá»­a chá»¯a hoáº·c thay tháº¿",
        "Kiá»ƒm tra cÃ¡c bá»™ pháº­n liÃªn quan cÃ³ bá»‹ áº£nh hÆ°á»Ÿng khÃ´ng",
        "LÃªn káº¿ hoáº¡ch thay tháº¿ phá»¥ tÃ¹ng",
        "RÃ  soÃ¡t láº¡i quy trÃ¬nh báº£o trÃ¬ Ä‘á»‹nh ká»³",
    ],
    "Ã‚m thanh báº¥t thÆ°á»ng": [
        "XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ vÃ  Ä‘áº·c Ä‘iá»ƒm Ã¢m thanh",
        "Kiá»ƒm tra cÃ¡c bá»™ pháº­n quay: báº¡c Ä‘áº¡n, trá»¥c, bÃ¡nh rÄƒng",
        "Kiá»ƒm tra há»‡ thá»‘ng truyá»n Ä‘á»™ng (dÃ¢y Ä‘ai, xÃ­ch)",
        "Kiá»ƒm tra lá»ng káº¿t ná»‘i cÆ¡ khÃ­",
        "Sá»­ dá»¥ng stethoscope cÃ´ng nghiá»‡p Ä‘á»ƒ cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c",
    ],
    "Giáº£m hiá»‡u suáº¥t": [
        "Kiá»ƒm tra Ä‘iá»u kiá»‡n Ä‘áº§u vÃ o (Ä‘iá»‡n, khÃ­, nÆ°á»›c)",
        "Kiá»ƒm tra bá»™ lá»c â€” vá»‡ sinh hoáº·c thay tháº¿",
        "Kiá»ƒm tra há»‡ thá»‘ng truyá»n Ä‘á»™ng â€” dÃ¢y Ä‘ai, ly há»£p",
        "ÄÃ¡nh giÃ¡ láº¡i thÃ´ng sá»‘ váº­n hÃ nh",
        "LÃªn káº¿ hoáº¡ch báº£o trÃ¬ tá»•ng thá»ƒ",
    ],
    "_default": [
        "Tiáº¿p tá»¥c theo dÃµi thiáº¿t bá»‹",
        "Báº£o dÆ°á»¡ng Ä‘á»‹nh ká»³ theo káº¿ hoáº¡ch",
        "Ghi nháº­n tÃ¬nh tráº¡ng Ä‘á»ƒ theo dÃµi xu hÆ°á»›ng",
    ],
}


# AnalysisResult imported from base_engine.py


# ============================================================
# 6. PhoBERT ENGINE CLASS
# ============================================================

class PhoBERTEngine(BaseNLPEngine):
    """
    PhoBERT Engine cho phÃ¢n tÃ­ch thiáº¿t bá»‹ cÃ´ng nghiá»‡p.

    Pipeline:
    1. Tiá»n xá»­ lÃ½ vÄƒn báº£n (normalize, clean)
    2. PhoBERT Tokenization & Encoding
    3. Cosine Similarity vá»›i cÃ¡c máº«u lá»—i tham chiáº¿u
    4. PhÃ¢n loáº¡i lá»—i (semantic classification)
    5. TrÃ­ch xuáº¥t keyword (supplementary)
    6. ÄÃ¡nh giÃ¡ severity
    7. Sinh khuyáº¿n nghá»‹
    """

    @property
    def name(self) -> str:
        return "phobert"

    def __init__(self):
        self.tokenizer = _tokenizer
        self.model = _model
        self.device = _device
        self.fault_refs = FAULT_REFERENCES
        self.recommendations_db = RECOMMENDATIONS_DB

        # Pre-compute embeddings cho cÃ¡c máº«u tham chiáº¿u
        self.ref_embeddings = {}
        self._precompute_reference_embeddings()

    def _precompute_reference_embeddings(self):
        """TÃ­nh trÆ°á»›c embeddings cho táº¥t cáº£ máº«u tham chiáº¿u."""
        print("ğŸ”„ Pre-computing reference embeddings...")
        for fault_name, fault_data in self.fault_refs.items():
            embeddings = []
            for sample in fault_data["samples"]:
                emb = self._encode_text(sample)
                embeddings.append(emb)
            # Láº¥y trung bÃ¬nh cÃ¡c embeddings lÃ m Ä‘áº¡i diá»‡n cho loáº¡i lá»—i
            self.ref_embeddings[fault_name] = torch.stack(embeddings).mean(dim=0)
        print("âœ… Reference embeddings ready")

    # ----------------------------------------------------------
    # PhoBERT Encoding
    # ----------------------------------------------------------
    @torch.no_grad()
    def _encode_text(self, text: str) -> torch.Tensor:
        """
        Encode text thÃ nh embedding vector sá»­ dá»¥ng PhoBERT.
        Tráº£ vá» [CLS] token embedding (768-dim).
        """
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=256,
        ).to(self.device)

        outputs = self.model(**inputs)
        # Láº¥y [CLS] token (vá»‹ trÃ­ 0) tá»« last hidden state
        cls_embedding = outputs.last_hidden_state[:, 0, :]
        return cls_embedding.squeeze(0).cpu()

    # ----------------------------------------------------------
    # Step 1: Text Preprocessing
    # ----------------------------------------------------------
    def preprocess(self, text: str) -> str:
        """Tiá»n xá»­ lÃ½ vÄƒn báº£n tiáº¿ng Viá»‡t."""
        text = unicodedata.normalize("NFC", text)
        text = text.lower()
        text = re.sub(r'[^\w\sÃ Ã¡áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»©á»«á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    # ----------------------------------------------------------
    # Step 2: Keyword Extraction (supplementary)
    # ----------------------------------------------------------
    def extract_keywords(self, text: str) -> list:
        """
        TrÃ­ch xuáº¥t tá»« khÃ³a triá»‡u chá»©ng tá»« text.
        Bá»• sung cho PhoBERT â€” giÃºp hiá»ƒn thá»‹ keywords cho user.
        """
        found = []
        negated_spans = []

        # Collect all keywords, sort by length desc
        all_kw = []
        for category, keywords in SYMPTOM_KEYWORDS.items():
            for kw in keywords:
                all_kw.append((kw, category))
        all_kw.sort(key=lambda x: len(x[0]), reverse=True)

        matched_spans = []

        for kw, category in all_kw:
            pattern = re.compile(re.escape(kw), re.IGNORECASE)
            for match in pattern.finditer(text):
                start, end = match.span()

                # Check if in negated span
                in_negated = any(start >= ns and end <= ne for ns, ne in negated_spans)
                if in_negated:
                    continue

                # Check negation
                lookback = max(0, start - 25)
                preceding = text[lookback:start].strip().lower()
                is_neg = any(preceding.endswith(neg) for neg in NEGATION_WORDS)
                if is_neg:
                    negated_spans.append((start, end))
                    continue

                # Check overlap
                is_overlap = any(start < me and end > ms for ms, me in matched_spans)
                if not is_overlap:
                    matched_spans.append((start, end))
                    found.append({"keyword": kw, "category": category})

        return found

    # ----------------------------------------------------------
    # Step 3: Semantic Fault Classification (PhoBERT)
    # ----------------------------------------------------------
    def classify_fault_phobert(self, text: str) -> list:
        """
        PhÃ¢n loáº¡i lá»—i báº±ng PhoBERT cosine similarity.
        Returns: danh sÃ¡ch (fault_name, similarity_score) Ä‘Ã£ sáº¯p xáº¿p giáº£m dáº§n.
        """
        text_embedding = self._encode_text(text)

        scores = []
        for fault_name, ref_emb in self.ref_embeddings.items():
            similarity = torch.nn.functional.cosine_similarity(
                text_embedding.unsqueeze(0),
                ref_emb.unsqueeze(0),
            ).item()
            scores.append((fault_name, similarity))

        # Sáº¯p xáº¿p giáº£m dáº§n theo similarity
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores

    # ----------------------------------------------------------
    # Step 4: Severity Assessment
    # ----------------------------------------------------------
    def assess_severity(self, fault_type: str, similarity: float, keywords: list) -> tuple:
        """
        ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng.
        Káº¿t há»£p: PhoBERT similarity + severity_base cá»§a loáº¡i lá»—i + sá»‘ keyword.
        """
        fault_data = self.fault_refs.get(fault_type, {})
        severity_base = fault_data.get("severity_base", 0.3)

        # Káº¿t há»£p severity: base * similarity + keyword bonus
        keyword_bonus = min(len(keywords) * 0.05, 0.2)
        severity_score = min(severity_base * similarity + keyword_bonus, 1.0)
        severity_score = round(severity_score, 2)

        if severity_score >= 0.65:
            return ("NGHIÃŠM TRá»ŒNG", severity_score)
        elif severity_score >= 0.40:
            return ("Cáº¢NH BÃO", severity_score)
        else:
            return ("THáº¤P", severity_score)

    # ----------------------------------------------------------
    # Step 5: Summary Generation
    # ----------------------------------------------------------
    def generate_summary(self, equipment: str, fault_type: str, severity: str, keywords: list, similarity: float) -> str:
        """Táº¡o tÃ³m táº¯t."""
        if fault_type == "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh":
            return f"{equipment} â€” khÃ´ng phÃ¡t hiá»‡n triá»‡u chá»©ng báº¥t thÆ°á»ng. Thiáº¿t bá»‹ cÃ³ thá»ƒ Ä‘ang hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng."

        fault_desc = self.fault_refs.get(fault_type, {}).get("description", fault_type)
        kw_list = ", ".join([k["keyword"] for k in keywords]) if keywords else "khÃ´ng rÃµ"

        summary = f"{equipment} â€” PhoBERT phÃ¢n loáº¡i: {fault_type} (similarity: {similarity:.1%}). "
        summary += f"Tá»« khÃ³a phÃ¡t hiá»‡n: {kw_list}. "
        summary += f"MÃ´ táº£: {fault_desc}. Má»©c Ä‘á»™: {severity}."
        return summary

    # ----------------------------------------------------------
    # MAIN PIPELINE
    # ----------------------------------------------------------
    def analyze(self, equipment: str, description: str) -> AnalysisResult:
        """
        Main NLP pipeline sá»­ dá»¥ng PhoBERT.

        Args:
            equipment: Loáº¡i thiáº¿t bá»‹
            description: MÃ´ táº£ tá»± nhiÃªn tiáº¿ng Viá»‡t

        Returns:
            AnalysisResult
        """
        t0 = time.perf_counter()
        pipeline_steps = []

        # Step 1: Preprocessing
        cleaned = self.preprocess(description)
        pipeline_steps.append({
            "step": 1,
            "name": "Tiá»n xá»­ lÃ½ vÄƒn báº£n",
            "input": description,
            "output": cleaned,
        })

        # Step 2: PhoBERT Tokenization
        tokens = self.tokenizer.tokenize(cleaned)
        pipeline_steps.append({
            "step": 2,
            "name": "PhoBERT Tokenization",
            "input": cleaned,
            "output": tokens,
        })

        # Step 3: Keyword Extraction
        keywords = self.extract_keywords(cleaned)
        pipeline_steps.append({
            "step": 3,
            "name": "TrÃ­ch xuáº¥t tá»« khÃ³a",
            "input": cleaned,
            "output": keywords,
        })

        # Step 4: PhoBERT Semantic Classification
        scores = self.classify_fault_phobert(cleaned)
        top_5 = scores[:5]

        pipeline_steps.append({
            "step": 4,
            "name": "PhoBERT PhÃ¢n loáº¡i lá»—i (Cosine Similarity)",
            "input": "PhoBERT embedding (768-dim)",
            "output": [{
                "fault": ("âœ… " if self.fault_refs.get(f, {}).get("is_normal", False) else "âš ï¸ ") + f,
                "similarity": round(s, 4),
            } for f, s in top_5],
        })

        # --- KEYWORD-AWARE RE-RANKING ---
        # Káº¿t há»£p PhoBERT similarity vá»›i keyword detection
        # Náº¿u cÃ³ keywords thuá»™c category nÃ o â†’ boost fault type liÃªn quan
        keyword_categories = set(k["category"] for k in keywords)

        # Mapping category â†’ related fault types
        CATEGORY_FAULT_MAP = {
            "Nhiá»‡t Ä‘á»™": ["QuÃ¡ nhiá»‡t", "ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor", "QuÃ¡ táº£i cÆ¡ khÃ­"],
            "Rung Ä‘á»™ng": ["Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi", "QuÃ¡ táº£i cÆ¡ khÃ­"],
            "Ã‚m thanh": ["Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi", "Ã‚m thanh báº¥t thÆ°á»ng"],
            "MÃ¹i": ["ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor"],
            "Äiá»‡n": ["Sá»± cá»‘ Ä‘iá»‡n", "ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor"],
            "RÃ² rá»‰": ["RÃ² rá»‰ há»‡ thá»‘ng"],
            "CÆ¡ khÃ­": ["HÆ° há»ng cÆ¡ khÃ­", "Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi"],
            "Hiá»‡u suáº¥t": ["Giáº£m hiá»‡u suáº¥t", "QuÃ¡ táº£i cÆ¡ khÃ­"],
        }

        # Boost scores dá»±a trÃªn keyword categories
        boosted_scores = []
        for fault_name, sim in scores:
            boost = 0.0
            for cat in keyword_categories:
                related = CATEGORY_FAULT_MAP.get(cat, [])
                if fault_name in related:
                    boost += 0.1  # Boost 0.1 cho má»—i category match
            boosted_scores.append((fault_name, sim + boost))

        boosted_scores.sort(key=lambda x: x[1], reverse=True)
        top_fault, top_score = boosted_scores[0]
        top_sim = dict(scores)[top_fault]  # Original similarity (khÃ´ng boost)

        # --- DECISION LOGIC ---
        # Chá»‰ phÃ¢n loáº¡i "BÃ¬nh thÆ°á»ng" khi Cáº¢ HAI Ä‘iá»u kiá»‡n Ä‘Ãºng:
        #   1. PhoBERT top match lÃ  "BÃ¬nh thÆ°á»ng"   VÃ€
        #   2. KhÃ´ng phÃ¡t hiá»‡n keyword triá»‡u chá»©ng nÃ o
        # Náº¿u cÃ³ keyword â†’ bá» qua "BÃ¬nh thÆ°á»ng", chá»n loáº¡i lá»—i cao nháº¥t tiáº¿p theo
        is_normal = self.fault_refs.get(top_fault, {}).get("is_normal", False)

        # Náº¿u top lÃ  "BÃ¬nh thÆ°á»ng" NHÆ¯NG cÃ³ keywords â†’ chá»n fault type tiáº¿p theo
        if is_normal and len(keywords) > 0:
            for fname, fscore in boosted_scores:
                if not self.fault_refs.get(fname, {}).get("is_normal", False):
                    top_fault = fname
                    top_score = fscore
                    top_sim = dict(scores)[fname]
                    break
            is_normal = False  # ÄÃ£ chuyá»ƒn sang fault type khÃ¡c

        if is_normal and len(keywords) == 0:
            fault_type = "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh"
            severity = "THáº¤P"
            severity_score = 0.0
            confidence = round(top_sim, 2)
            recommendations = RECOMMENDATIONS_DB["_default"]
        else:
            fault_type = top_fault
            severity, severity_score = self.assess_severity(fault_type, top_sim, keywords)
            confidence = round(top_sim, 2)
            recommendations = self.recommendations_db.get(fault_type, self.recommendations_db["_default"])

        pipeline_steps.append({
            "step": 5,
            "name": "ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng",
            "input": f"fault={fault_type}, similarity={top_sim:.4f}, keywords={len(keywords)}",
            "output": {"severity": severity, "score": severity_score},
        })

        # Step 6: Recommendations
        pipeline_steps.append({
            "step": 6,
            "name": "Sinh khuyáº¿n nghá»‹",
            "input": fault_type,
            "output": recommendations,
        })

        # Summary
        summary = self.generate_summary(equipment, fault_type, severity, keywords, top_sim)

        elapsed_ms = (time.perf_counter() - t0) * 1000

        return AnalysisResult(
            fault_type=fault_type,
            severity=severity,
            severity_score=severity_score,
            confidence=confidence,
            keywords=[k["keyword"] for k in keywords],
            symptoms=[{
                "keyword": k["keyword"],
                "category": k["category"],
                "label": k["keyword"],
                "weight": 3,
            } for k in keywords],
            recommendations=recommendations,
            summary=summary,
            pipeline_steps=pipeline_steps,
            engine_name=self.name,
            engine_latency_ms=round(elapsed_ms, 2),
        )


# ============================================================
# SINGLETON & CONVENIENCE
# ============================================================

engine = PhoBERTEngine()


def analyze(equipment: str, description: str) -> AnalysisResult:
    """Convenience function â€” gá»i engine.analyze()."""
    return engine.analyze(equipment, description)
