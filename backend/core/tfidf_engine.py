"""
TF-IDF Engine â€” Vietnamese Industrial Equipment Fault Analysis
================================================================
Sá»­ dá»¥ng TF-IDF + Logistic Regression/SVM (pre-trained) Ä‘á»ƒ phÃ¢n loáº¡i lá»—i.
Lightweight & fast inference so vá»›i PhoBERT.

Pipeline:
  Input text â†’ TF-IDF vectorize â†’ Classifier predict â†’ AnalysisResult
"""
import json
import time
from pathlib import Path

import joblib
import numpy as np

from backend.core.base_engine import BaseNLPEngine, AnalysisResult


# Model directory
_MODEL_DIR = Path(__file__).resolve().parent.parent / "resources" / "tfidf"


# ============================================================
# SEVERITY & RECOMMENDATION MAPPINGS
# ============================================================

SEVERITY_MAP = {
    "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh": ("BÃŒNH THÆ¯á»œNG", 0.0),
    "QuÃ¡ nhiá»‡t": ("NGHIÃŠM TRá»ŒNG", 0.7),
    "Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi": ("NGHIÃŠM TRá»ŒNG", 0.75),
    "ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor": ("NGHIÃŠM TRá»ŒNG", 0.9),
    "Sá»± cá»‘ Ä‘iá»‡n": ("NGHIÃŠM TRá»ŒNG", 0.85),
    "QuÃ¡ táº£i cÆ¡ khÃ­": ("Cáº¢NH BÃO", 0.8),
    "RÃ² rá»‰ há»‡ thá»‘ng": ("Cáº¢NH BÃO", 0.5),
    "HÆ° há»ng cÆ¡ khÃ­": ("Cáº¢NH BÃO", 0.6),
    "Ã‚m thanh báº¥t thÆ°á»ng": ("Cáº¢NH BÃO", 0.5),
    "Giáº£m hiá»‡u suáº¥t": ("Cáº¢NH BÃO", 0.55),
}

RECOMMENDATIONS_MAP = {
    "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh": [
        "Tiáº¿p tá»¥c váº­n hÃ nh bÃ¬nh thÆ°á»ng",
        "LÃªn lá»‹ch báº£o trÃ¬ Ä‘á»‹nh ká»³ theo káº¿ hoáº¡ch",
    ],
    "QuÃ¡ nhiá»‡t": [
        "Dá»«ng thiáº¿t bá»‹ ngay, Ä‘á»ƒ nguá»™i trÆ°á»›c khi kiá»ƒm tra",
        "Kiá»ƒm tra há»‡ thá»‘ng lÃ m mÃ¡t, quáº¡t táº£n nhiá»‡t",
        "Kiá»ƒm tra dáº§u bÃ´i trÆ¡n, tra dáº§u náº¿u thiáº¿u",
    ],
    "Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi": [
        "Dá»«ng mÃ¡y ngay Ä‘á»ƒ trÃ¡nh hÆ° há»ng lan rá»™ng",
        "Thay tháº¿ báº¡c Ä‘áº¡n / vÃ²ng bi bá»‹ há»ng",
        "Kiá»ƒm tra trá»¥c mÃ¡y, cÃ¢n chá»‰nh láº¡i",
    ],
    "ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor": [
        "NGáº®T ÄIá»†N NGAY Láº¬P Tá»¨C",
        "KhÃ´ng cá»‘ khá»Ÿi Ä‘á»™ng láº¡i, chá» kiá»ƒm tra chuyÃªn gia",
        "Kiá»ƒm tra cÃ¡ch Ä‘iá»‡n cuá»™n dÃ¢y, thay motor náº¿u cáº§n",
    ],
    "Sá»± cá»‘ Ä‘iá»‡n": [
        "Ngáº¯t nguá»“n Ä‘iá»‡n ngay, kiá»ƒm tra an toÃ n",
        "Kiá»ƒm tra cáº§u chÃ¬, relay báº£o vá»‡",
        "Kiá»ƒm tra dÃ¢y dáº«n, Ä‘áº§u ná»‘i, tiáº¿p xÃºc Ä‘iá»‡n",
    ],
    "QuÃ¡ táº£i cÆ¡ khÃ­": [
        "Giáº£m táº£i ngay cho thiáº¿t bá»‹",
        "Kiá»ƒm tra dÃ¢y Ä‘ai, khá»›p ná»‘i truyá»n Ä‘á»™ng",
        "XÃ¡c Ä‘á»‹nh nguyÃªn nhÃ¢n quÃ¡ táº£i, Ä‘iá»u chá»‰nh cÃ´ng suáº¥t",
    ],
    "RÃ² rá»‰ há»‡ thá»‘ng": [
        "XÃ¡c Ä‘á»‹nh vá»‹ trÃ­ rÃ² rá»‰ chÃ­nh xÃ¡c",
        "Thay tháº¿ gioÄƒng, phá»›t, seal bá»‹ há»ng",
        "Kiá»ƒm tra Ã¡p suáº¥t há»‡ thá»‘ng sau sá»­a chá»¯a",
    ],
    "HÆ° há»ng cÆ¡ khÃ­": [
        "Dá»«ng mÃ¡y, Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ hÆ° há»ng",
        "Thay tháº¿ chi tiáº¿t bá»‹ há»ng (bu lÃ´ng, dÃ¢y Ä‘ai, trá»¥c)",
        "Kiá»ƒm tra cÃ¢n báº±ng, láº¯p Ä‘áº·t láº¡i thiáº¿t bá»‹",
    ],
    "Ã‚m thanh báº¥t thÆ°á»ng": [
        "Giáº£m táº£i hoáº·c dá»«ng mÃ¡y Ä‘á»ƒ kiá»ƒm tra",
        "XÃ¡c Ä‘á»‹nh nguá»“n phÃ¡t ra Ã¢m thanh láº¡",
        "Kiá»ƒm tra báº¡c Ä‘áº¡n, bÃ¡nh rÄƒng, dÃ¢y Ä‘ai",
    ],
    "Giáº£m hiá»‡u suáº¥t": [
        "Kiá»ƒm tra nguá»“n Ä‘iá»‡n cung cáº¥p",
        "Kiá»ƒm tra táº£i, giáº£m táº£i náº¿u quÃ¡ má»©c",
        "Kiá»ƒm tra bá»™ Ä‘iá»u khiá»ƒn, sensor, relay",
    ],
}


class TFIDFEngine(BaseNLPEngine):
    """
    TF-IDF + Classical ML Engine cho phÃ¢n tÃ­ch thiáº¿t bá»‹ cÃ´ng nghiá»‡p.
    Lightweight, fast inference (~1-2ms so vá»›i ~30-50ms PhoBERT).
    """

    @property
    def name(self) -> str:
        return "tfidf"

    def __init__(self):
        """Load pre-trained vectorizer, classifier, label encoder."""
        print("ðŸ”„ Loading TF-IDF model artifacts...")

        self.vectorizer = joblib.load(_MODEL_DIR / "vectorizer.pkl")
        self.classifier = joblib.load(_MODEL_DIR / "classifier.pkl")
        self.label_encoder = joblib.load(_MODEL_DIR / "label_encoder.pkl")

        # Load metadata for version info
        meta_path = _MODEL_DIR / "metadata.json"
        if meta_path.exists():
            with open(meta_path, "r", encoding="utf-8") as f:
                self.metadata = json.load(f)
        else:
            self.metadata = {}

        print(f"âœ… TF-IDF model loaded (v{self.metadata.get('version', '?')})")
        print(f"   Classifier: {self.metadata.get('classifier', '?')}")
        print(f"   Classes: {len(self.label_encoder.classes_)}")

    def analyze(self, equipment: str, description: str) -> AnalysisResult:
        """
        PhÃ¢n tÃ­ch thiáº¿t bá»‹ báº±ng TF-IDF pipeline.

        Args:
            equipment: Loáº¡i thiáº¿t bá»‹
            description: MÃ´ táº£ tÃ¬nh tráº¡ng thiáº¿t bá»‹

        Returns:
            AnalysisResult
        """
        t0 = time.perf_counter()
        pipeline_steps = []

        # Step 1: TF-IDF vectorize
        X = self.vectorizer.transform([description])
        pipeline_steps.append({
            "step": 1,
            "name": "TF-IDF Vectorization",
            "output": f"Sparse vector: {X.shape}",
        })

        # Step 2: Predict class
        y_pred = self.classifier.predict(X)[0]
        fault_type = self.label_encoder.inverse_transform([y_pred])[0]

        # Step 3: Confidence score
        if hasattr(self.classifier, "predict_proba"):
            proba = self.classifier.predict_proba(X)[0]
            confidence = float(np.max(proba))
        elif hasattr(self.classifier, "decision_function"):
            decision = self.classifier.decision_function(X)[0]
            # Convert decision function to pseudo-probability via softmax
            exp_d = np.exp(decision - np.max(decision))
            proba = exp_d / exp_d.sum()
            confidence = float(np.max(proba))
        else:
            confidence = 0.0

        pipeline_steps.append({
            "step": 2,
            "name": "Classification",
            "output": f"{fault_type} (confidence: {confidence:.4f})",
        })

        # Step 4: Severity
        severity, severity_score = SEVERITY_MAP.get(
            fault_type, ("Cáº¢NH BÃO", 0.5)
        )

        # Adjust severity_score by confidence
        severity_score = round(severity_score * confidence, 3)

        pipeline_steps.append({
            "step": 3,
            "name": "Severity Assessment",
            "output": f"{severity} (score: {severity_score})",
        })

        # Step 5: Extract keywords from TF-IDF features
        feature_names = self.vectorizer.get_feature_names_out()
        tfidf_scores = X.toarray()[0]
        top_indices = tfidf_scores.argsort()[-5:][::-1]
        keywords = [
            feature_names[i] for i in top_indices if tfidf_scores[i] > 0
        ]

        pipeline_steps.append({
            "step": 4,
            "name": "Keyword Extraction (TF-IDF top features)",
            "output": keywords,
        })

        # Step 6: Recommendations
        recommendations = RECOMMENDATIONS_MAP.get(fault_type, [
            "Kiá»ƒm tra thiáº¿t bá»‹",
            "LiÃªn há»‡ ká»¹ thuáº­t viÃªn",
        ])

        # Step 7: Summary
        summary = (
            f"[TF-IDF] Thiáº¿t bá»‹ '{equipment}': {fault_type}. "
            f"Má»©c Ä‘á»™: {severity} ({severity_score}). "
            f"Tá»« khÃ³a: {', '.join(keywords[:3])}."
        )

        elapsed_ms = (time.perf_counter() - t0) * 1000

        return AnalysisResult(
            fault_type=fault_type,
            severity=severity,
            severity_score=severity_score,
            confidence=round(confidence, 4),
            keywords=keywords,
            symptoms=[{
                "keyword": k,
                "category": "tfidf_feature",
                "label": k,
                "weight": 3,
            } for k in keywords],
            recommendations=recommendations,
            summary=summary,
            pipeline_steps=pipeline_steps,
            engine_name=self.name,
            engine_latency_ms=round(elapsed_ms, 2),
        )
