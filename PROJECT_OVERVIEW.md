# ğŸ“‹ Tá»•ng Há»£p Project: NLP Equipment Fault Analysis System

## 1. MÃ´ táº£ tá»•ng quan

ÄÃ¢y lÃ  há»‡ thá»‘ng **phÃ¢n tÃ­ch cáº£nh bÃ¡o lá»—i thiáº¿t bá»‹ cÃ´ng nghiá»‡p** sá»­ dá»¥ng **NLP (Natural Language Processing)** vá»›i model **PhoBERT** (`vinai/phobert-base`). Há»‡ thá»‘ng nháº­n Ä‘áº§u vÃ o lÃ  **mÃ´ táº£ báº±ng ngÃ´n ngá»¯ tiáº¿ng Viá»‡t** vá» tÃ¬nh tráº¡ng thiáº¿t bá»‹, sau Ä‘Ã³ tá»± Ä‘á»™ng phÃ¢n loáº¡i lá»—i, Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng, vÃ  Ä‘Æ°a ra khuyáº¿n nghá»‹ xá»­ lÃ½.

---

## 2. Kiáº¿n trÃºc há»‡ thá»‘ng

```mermaid
graph TB
    subgraph Frontend
        UI["ui.html<br/>Giao diá»‡n web"]
    end

    subgraph Backend["Backend (FastAPI)"]
        APP["app.py<br/>API Routes"]
        NLP["nlp_engine.py<br/>PhoBERT NLP Engine"]
        DB["database.py<br/>SQLite Database"]
        SCH["schemas.py<br/>Pydantic Models"]
    end

    subgraph Resources
        MODEL["phobert-base/<br/>Pre-trained Model"]
        DBFILE["history.db<br/>SQLite DB File"]
        BG["bg.png<br/>Background Image"]
    end

    UI -->|"POST /analyze"| APP
    UI -->|"GET /history"| APP
    APP --> NLP
    APP --> DB
    NLP --> MODEL
    DB --> DBFILE
    UI --> BG
```

## 3. Cáº¥u trÃºc thÆ° má»¥c

```
nlp/
â”œâ”€â”€ main.py                          # Entry point â€” Uvicorn server (port 10805)
â”œâ”€â”€ test_e2e.py                      # E2E tests (10 test cases)
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                       # FastAPI app + API routes
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ nlp_engine.py            # â­ NLP Engine (PhoBERT) â€” 659 dÃ²ng
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ database.py              # SQLite CRUD operations
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ schemas.py               # Pydantic request/response models
â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”œâ”€â”€ phobert-base/            # PhoBERT model files
â”‚   â”‚   â””â”€â”€ database/history.db      # SQLite database
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ test_engine.py           # Unit tests cho NLP Engine
â”‚       â””â”€â”€ test_phase2.py           # Integration tests
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ ui.html                  # Single-page web UI (1276 dÃ²ng)
    â””â”€â”€ images/
        â””â”€â”€ bg.png                   # Background image
```

## 4. NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng â€” NLP Pipeline

Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng theo quy trÃ¬nh **6 bÆ°á»›c** (pipeline):

```mermaid
graph LR
    A["ğŸ“ VÄƒn báº£n<br/>tiáº¿ng Viá»‡t"] --> B["1. Tiá»n xá»­ lÃ½"]
    B --> C["2. PhoBERT<br/>Tokenization"]
    C --> D["3. TrÃ­ch xuáº¥t<br/>tá»« khÃ³a"]
    D --> E["4. PhÃ¢n loáº¡i lá»—i<br/>Cosine Similarity"]
    E --> F["5. ÄÃ¡nh giÃ¡<br/>má»©c Ä‘á»™"]
    F --> G["6. Sinh<br/>khuyáº¿n nghá»‹"]
```

### BÆ°á»›c 1ï¸âƒ£ â€” Tiá»n xá»­ lÃ½ vÄƒn báº£n
- Normalize Unicode (NFC)
- Chuyá»ƒn lowercase
- Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, giá»¯ láº¡i tiáº¿ng Viá»‡t cÃ³ dáº¥u
- Chuáº©n hÃ³a khoáº£ng tráº¯ng

### BÆ°á»›c 2ï¸âƒ£ â€” PhoBERT Tokenization & Encoding
- Tokenize text báº±ng PhoBERT tokenizer
- Encode thÃ nh **embedding vector 768 chiá»u** sá»­ dá»¥ng `[CLS]` token tá»« last hidden state
- Model cháº¡y á»Ÿ cháº¿ Ä‘á»™ **inference** (CPU mode)

### BÆ°á»›c 3ï¸âƒ£ â€” TrÃ­ch xuáº¥t tá»« khÃ³a (Keyword Extraction)
- So khá»›p vÄƒn báº£n vá»›i **SYMPTOM_KEYWORDS** database (8 nhÃ³m: Nhiá»‡t Ä‘á»™, Rung Ä‘á»™ng, Ã‚m thanh, MÃ¹i, Äiá»‡n, RÃ² rá»‰, CÆ¡ khÃ­, Hiá»‡u suáº¥t)
- Xá»­ lÃ½ **negation** (phá»§ Ä‘á»‹nh): nháº­n biáº¿t "khÃ´ng nÃ³ng", "khÃ´ng rung" â†’ loáº¡i bá» keyword bá»‹ phá»§ Ä‘á»‹nh
- TrÃ¡nh overlap giá»¯a cÃ¡c keyword

### BÆ°á»›c 4ï¸âƒ£ â€” PhÃ¢n loáº¡i lá»—i báº±ng PhoBERT (Semantic Classification)
ÄÃ¢y lÃ  **bÆ°á»›c cá»‘t lÃµi** cá»§a há»‡ thá»‘ng:

1. **Pre-compute**: Khi khá»Ÿi táº¡o, engine tÃ­nh trÆ°á»›c embeddings cho **10 loáº¡i lá»—i** tham chiáº¿u (má»—i loáº¡i cÃ³ 5-15 cÃ¢u máº«u)
2. **Cosine Similarity**: So sÃ¡nh embedding cá»§a text input vá»›i embedding trung bÃ¬nh cá»§a má»—i loáº¡i lá»—i
3. **Keyword-aware Re-ranking**: Boost score cÃ¡c loáº¡i lá»—i liÃªn quan Ä‘áº¿n keyword Ä‘Ã£ phÃ¡t hiá»‡n (+0.1/category)
4. **Decision Logic**: Náº¿u top result lÃ  "BÃ¬nh thÆ°á»ng" hoáº·c khÃ´ng cÃ³ keyword â†’ "Hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh"

| Loáº¡i lá»—i | Severity Base |
|---|---|
| BÃ¬nh thÆ°á»ng | 0.0 |
| RÃ² rá»‰ há»‡ thá»‘ng | 0.5 |
| Ã‚m thanh báº¥t thÆ°á»ng | 0.5 |
| Giáº£m hiá»‡u suáº¥t | 0.55 |
| HÆ° há»ng cÆ¡ khÃ­ | 0.6 |
| QuÃ¡ nhiá»‡t | 0.7 |
| Há»ng báº¡c Ä‘áº¡n / vÃ²ng bi | 0.75 |
| QuÃ¡ táº£i cÆ¡ khÃ­ | 0.8 |
| Sá»± cá»‘ Ä‘iá»‡n | 0.85 |
| ChÃ¡y cuá»™n dÃ¢y / chÃ¡y motor | 0.9 |

### BÆ°á»›c 5ï¸âƒ£ â€” ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ nghiÃªm trá»ng (Severity Assessment)
CÃ´ng thá»©c: `severity_score = severity_base Ã— similarity + keyword_bonus`
- `keyword_bonus = min(sá»‘_keyword Ã— 0.05, 0.2)`

| Score | Má»©c Ä‘á»™ |
|---|---|
| â‰¥ 0.65 | ğŸ”´ **NGHIÃŠM TRá»ŒNG** |
| â‰¥ 0.40 | ğŸŸ¡ **Cáº¢NH BÃO** |
| < 0.40 | ğŸŸ¢ **THáº¤P** |

### BÆ°á»›c 6ï¸âƒ£ â€” Sinh khuyáº¿n nghá»‹
- Tra cá»©u `RECOMMENDATIONS_DB` theo loáº¡i lá»—i Ä‘Ã£ phÃ¢n loáº¡i
- Má»—i loáº¡i lá»—i cÃ³ 4-6 khuyáº¿n nghá»‹ xá»­ lÃ½ cá»¥ thá»ƒ

---

## 5. API Endpoints

| Method | Path | MÃ´ táº£ |
|---|---|---|
| `GET` | `/` | Serve giao diá»‡n web |
| `POST` | `/analyze` | PhÃ¢n tÃ­ch NLP (equipment + description) |
| `GET` | `/history` | Láº¥y lá»‹ch sá»­ phÃ¢n tÃ­ch (phÃ¢n trang) |
| `GET` | `/history/{id}` | Chi tiáº¿t 1 báº£n ghi |
| `DELETE` | `/history/{id}` | XÃ³a 1 báº£n ghi |
| `DELETE` | `/history` | XÃ³a toÃ n bá»™ lá»‹ch sá»­ |

---

## 6. Stack cÃ´ng nghá»‡

| ThÃ nh pháº§n | CÃ´ng nghá»‡ |
|---|---|
| NLP Model | **PhoBERT** (vinai/phobert-base) â€” HuggingFace Transformers |
| Backend | **FastAPI** + Uvicorn |
| Database | **SQLite** |
| Frontend | **HTML/CSS/JS** (Single-page) |
| ML Framework | **PyTorch** (CPU mode) |
| Validation | **Pydantic** v2 |

---

## 7. Luá»“ng xá»­ lÃ½ chÃ­nh (Use Case)

```mermaid
sequenceDiagram
    actor User
    participant UI as Frontend (ui.html)
    participant API as FastAPI (app.py)
    participant NLP as NLP Engine (PhoBERT)
    participant DB as SQLite

    User->>UI: Nháº­p mÃ´ táº£ thiáº¿t bá»‹<br/>"Motor nÃ³ng báº¥t thÆ°á»ng, rung máº¡nh"
    UI->>API: POST /analyze<br/>{equipment, description}
    API->>NLP: nlp_analyze(equipment, description)
    NLP->>NLP: 1. Tiá»n xá»­ lÃ½
    NLP->>NLP: 2. PhoBERT Encoding (768-dim)
    NLP->>NLP: 3. Keyword Extraction
    NLP->>NLP: 4. Cosine Similarity â†’ Top fault
    NLP->>NLP: 5. Severity Assessment
    NLP->>NLP: 6. Recommendations
    NLP-->>API: AnalysisResult
    API->>DB: save_analysis()
    DB-->>API: record_id
    API-->>UI: AnalyzeResponse (JSON)
    UI-->>User: Hiá»ƒn thá»‹ káº¿t quáº£:<br/>Loáº¡i lá»—i, Má»©c Ä‘á»™, Keywords,<br/>Khuyáº¿n nghá»‹, Pipeline steps
```

## 8. Äáº·c Ä‘iá»ƒm ná»•i báº­t

- **Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn tiáº¿ng Viá»‡t**: Sá»­ dá»¥ng PhoBERT â€” model pre-trained dÃ nh riÃªng cho tiáº¿ng Viá»‡t
- **Semantic matching**: KhÃ´ng chá»‰ so khá»›p keyword mÃ  hiá»ƒu ngá»¯ nghÄ©a cÃ¢u vÄƒn
- **Negation handling**: Nháº­n biáº¿t phá»§ Ä‘á»‹nh ("khÃ´ng nÃ³ng" â‰  "nÃ³ng")
- **Keyword-aware re-ranking**: Káº¿t há»£p semantic (PhoBERT) + rule-based (keyword) Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c
- **Transparency**: Hiá»ƒn thá»‹ chi tiáº¿t tá»«ng bÆ°á»›c pipeline cho user
- **LÆ°u lá»‹ch sá»­**: Má»i káº¿t quáº£ phÃ¢n tÃ­ch Ä‘á»u Ä‘Æ°á»£c lÆ°u vÃ o SQLite Ä‘á»ƒ tra cá»©u láº¡i
