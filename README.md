# üîß NLP Equipment Fault Analysis System

H·ªá th·ªëng ph√¢n t√≠ch l·ªói thi·∫øt b·ªã c√¥ng nghi·ªáp b·∫±ng x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP), h·ªó tr·ª£ 2 engine: **PhoBERT** (zero-shot semantic similarity) v√† **TF-IDF** (Logistic Regression classifier).

---

## üìÅ C·∫•u tr√∫c d·ª± √°n

```
nlp/
‚îú‚îÄ‚îÄ main.py                          # Entry point ‚Äî ch·∫°y server
‚îú‚îÄ‚îÄ requirements.txt                 # Th∆∞ vi·ªán c·∫ßn c√†i
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app.py                       # FastAPI routes (/analyze, /history, ...)
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_engine.py           # Abstract base class cho engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ phobert_engine.py        # PhoBERT engine (semantic similarity)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tfidf_engine.py          # TF-IDF engine (classifier)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ engine_factory.py        # Factory pattern ch·ªçn engine
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py               # Pydantic schemas (request/response)
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py              # SQLite l∆∞u l·ªãch s·ª≠ ph√¢n t√≠ch
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_preparation.py      # T·∫°o training data t·ª´ FAULT_REFERENCES
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_tfidf.py           # Training pipeline TF-IDF
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                # C·∫•u h√¨nh training
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation_dataset.json  # Dataset ƒë√°nh gi√° (149 m·∫´u)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_evaluation.py        # Ch·∫°y ƒë√°nh gi√° engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py             # Predict helper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py               # T√≠nh metrics + confusion matrix
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ latency.py               # ƒêo latency
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ results/                 # K·∫øt qu·∫£ evaluation (auto-generated)
‚îÇ   ‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_engine.py           # Unit tests cho engine
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_phase2.py           # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ resources/
‚îÇ       ‚îî‚îÄ‚îÄ tfidf/                   # Model TF-IDF ƒë√£ train (auto-generated)
‚îî‚îÄ‚îÄ frontend/
    ‚îî‚îÄ‚îÄ templates/
        ‚îî‚îÄ‚îÄ ui.html                  # Giao di·ªán web
```

---

## üöÄ H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t & ch·∫°y

### B∆∞·ªõc 1: T·∫°o m√¥i tr∆∞·ªùng Conda

```bash
# T·∫°o environment m·ªõi v·ªõi Python 3.10
conda create -n mlops python=3.10 -y

# K√≠ch ho·∫°t environment
conda activate mlops
```

### B∆∞·ªõc 2: C√†i ƒë·∫∑t th∆∞ vi·ªán

```bash
# Di chuy·ªÉn v√†o th∆∞ m·ª•c d·ª± √°n
cd /mnt/atin/QuyNB/project/master_project/nlp

# C√†i ƒë·∫∑t t·∫•t c·∫£ th∆∞ vi·ªán
pip install -r requirements.txt
```

> **L∆∞u √Ω:** L·∫ßn ƒë·∫ßu ch·∫°y, PhoBERT model (~1.3GB) s·∫Ω t·ª± ƒë·ªông t·∫£i t·ª´ HuggingFace.

---

### B∆∞·ªõc 3: Training TF-IDF Model

```bash
# Train TF-IDF classifier t·ª´ FAULT_REFERENCES data
python -m backend.training.train_tfidf
```

**Output:** C√°c file model s·∫Ω ƒë∆∞·ª£c l∆∞u t·∫°i `backend/resources/tfidf/`:
- `vectorizer.pkl` ‚Äî TF-IDF vectorizer
- `classifier.pkl` ‚Äî Logistic Regression classifier
- `label_encoder.pkl` ‚Äî Label encoder
- `metadata.json` ‚Äî Metadata & version info

> ‚ö†Ô∏è **B·∫Øt bu·ªôc ch·∫°y b∆∞·ªõc n√†y tr∆∞·ªõc khi d√πng TF-IDF engine.** PhoBERT engine kh√¥ng c·∫ßn training.

---

### B∆∞·ªõc 4: Ch·∫°y server (Production)

```bash
# Ch·∫°y FastAPI server
python main.py
```

Server s·∫Ω ch·∫°y t·∫°i: **http://localhost:10805**

| Endpoint | Method | M√¥ t·∫£ |
|---|---|---|
| `/` | GET | Giao di·ªán web |
| `/analyze` | POST | Ph√¢n t√≠ch l·ªói thi·∫øt b·ªã |
| `/history` | GET | L·ªãch s·ª≠ ph√¢n t√≠ch |
| `/history/{id}` | GET | Chi ti·∫øt 1 b·∫£n ghi |
| `/docs` | GET | Swagger API docs |

**V√≠ d·ª• g·ªçi API:**

```bash
curl -X POST http://localhost:10805/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "equipment": "Motor b∆°m n∆∞·ªõc",
    "description": "Motor rung m·∫°nh k√®m ti·∫øng kim lo·∫°i va ch·∫°m",
    "engine": "phobert"
  }'
```

Tham s·ªë `engine` c√≥ th·ªÉ l√† `"phobert"` ho·∫∑c `"tfidf"`.

---

### B∆∞·ªõc 5: ƒê√°nh gi√° model (Evaluation)

```bash
# ƒê√°nh gi√° c·∫£ 2 engine
python -m backend.evaluation.run_evaluation --engine all

# ƒê√°nh gi√° ri√™ng t·ª´ng engine
python -m backend.evaluation.run_evaluation --engine phobert
python -m backend.evaluation.run_evaluation --engine tfidf
```

**Output:** K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u t·∫°i `backend/evaluation/results/`:
- `confusion_matrix_*.png` ‚Äî Ma tr·∫≠n nh·∫ßm l·∫´n
- `evaluation_report_*.json` ‚Äî B√°o c√°o chi ti·∫øt (JSON)
- `evaluation_report_*.txt` ‚Äî B√°o c√°o chi ti·∫øt (text)
- `comparison_report.json` ‚Äî So s√°nh 2 engine

---

### B∆∞·ªõc 6: Ch·∫°y tests

```bash
# Unit tests (kh√¥ng c·∫ßn server ƒëang ch·∫°y)
python -m backend.test.test_engine

# End-to-end tests (c·∫ßn server ƒëang ch·∫°y ·ªü b∆∞·ªõc 4)
python test_e2e.py
```

---

## üìä K·∫øt qu·∫£ ƒë√°nh gi√° hi·ªán t·∫°i

Dataset: **149 m·∫´u** (unseen data, 10 fault types)

| Metric | TF-IDF | PhoBERT |
|---|---|---|
| Accuracy | **89.26%** | 73.83% |
| F1 Macro | **0.8931** | 0.7402 |
| Latency | **2.9ms** | 31.0ms |

---

## üè∑Ô∏è 10 Lo·∫°i l·ªói h·ªó tr·ª£

| # | Lo·∫°i l·ªói | M√¥ t·∫£ |
|---|---|---|
| 1 | Ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh | Thi·∫øt b·ªã b√¨nh th∆∞·ªùng |
| 2 | Qu√° nhi·ªát | Nhi·ªát ƒë·ªô cao b·∫•t th∆∞·ªùng |
| 3 | H·ªèng b·∫°c ƒë·∫°n / v√≤ng bi | Rung + ti·∫øng kim lo·∫°i |
| 4 | Ch√°y cu·ªôn d√¢y / ch√°y motor | M√πi ch√°y + b·ªëc kh√≥i |
| 5 | S·ª± c·ªë ƒëi·ªán | Ch·∫≠p, r√≤, qu√° t·∫£i ƒëi·ªán |
| 6 | Qu√° t·∫£i c∆° kh√≠ | N√≥ng + rung do qu√° t·∫£i |
| 7 | R√≤ r·ªâ h·ªá th·ªëng | R√≤ d·∫ßu, n∆∞·ªõc, kh√≠ |
| 8 | H∆∞ h·ªèng c∆° kh√≠ | N·ª©t, g√£y, m√≤n, g·ªâ s√©t |
| 9 | √Çm thanh b·∫•t th∆∞·ªùng | Ti·∫øng ·ªìn, k√™u l·∫° |
| 10 | Gi·∫£m hi·ªáu su·∫•t | Ch·∫°y ch·∫≠m, y·∫øu, k√©m |
